{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQUk3Y0WwYZ4"
      },
      "source": [
        "# ü§ó x ü¶æ: Training ACT with LeRobot Notebook\n",
        "\n",
        "Welcome to the **LeRobot ACT training notebook**! This notebook provides a ready-to-run setup for training imitation learning policies using the [ü§ó LeRobot](https://github.com/huggingface/lerobot) library.\n",
        "\n",
        "In this example, we train an `ACT` policy using a dataset hosted on the [Hugging Face Hub](https://huggingface.co/), and optionally track training metrics with [Weights & Biases (wandb)](https://wandb.ai/).\n",
        "\n",
        "## ‚öôÔ∏è Requirements\n",
        "- A Hugging Face dataset repo ID containing your training data (`--dataset.repo_id=YOUR_USERNAME/YOUR_DATASET`)\n",
        "- Optional: A [wandb](https://wandb.ai/) account if you want to enable training visualization\n",
        "- Recommended: GPU runtime (e.g., NVIDIA A100) for faster training\n",
        "\n",
        "## ‚è±Ô∏è Expected Training Time\n",
        "Training with the `ACT` policy for 100,000 steps typically takes **about 1.5 hours on an NVIDIA A100** GPU. On less powerful GPUs or CPUs, training may take significantly longer.\n",
        "\n",
        "## Example Output\n",
        "Model checkpoints, logs, and training plots will be saved to the specified `--output_dir`. If `wandb` is enabled, progress will also be visualized in your wandb project dashboard.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOJyX0CnwA5m"
      },
      "source": [
        "## Install conda\n",
        "This cell uses `condacolab` to bootstrap a full Conda environment inside Google Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlKjL1X5t_zM",
        "outputId": "7a0d6133-b031-4884-eb75-82c83702253f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚è¨ Downloading https://github.com/jaimergp/miniforge/releases/download/24.11.2-1_colab/Miniforge3-colab-24.11.2-1_colab-Linux-x86_64.sh...\n",
            "üì¶ Installing...\n",
            "üìå Adjusting configuration...\n",
            "ü©π Patching environment...\n",
            "‚è≤ Done in 0:00:13\n",
            "üîÅ Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxCc3CARwUjN"
      },
      "source": [
        "## Install LeRobot\n",
        "This cell clones the `lerobot` repository from Hugging Face, installs FFmpeg (version 7.1.1), and installs the package in editable mode.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgLu7QT5tUik",
        "outputId": "d41357dc-7601-4604-d459-739320c55f27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'lerobot'...\n",
            "remote: Enumerating objects: 40244, done.\u001b[K\n",
            "remote: Counting objects: 100% (342/342), done.\u001b[K\n",
            "remote: Compressing objects: 100% (222/222), done.\u001b[K\n",
            "remote: Total 40244 (delta 253), reused 120 (delta 120), pack-reused 39902 (from 5)\u001b[K\n",
            "Receiving objects: 100% (40244/40244), 170.00 MiB | 31.10 MiB/s, done.\n",
            "Resolving deltas: 100% (26260/26260), done.\n",
            "Filtering content: 100% (45/45), 69.03 MiB | 38.33 MiB/s, done.\n",
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - ffmpeg=7.1.1\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    alsa-lib-1.2.14            |       hb9d3cd8_0         553 KB  conda-forge\n",
            "    aom-3.9.1                  |       hac33072_0         2.6 MB  conda-forge\n",
            "    attr-2.5.2                 |       h39aace5_0          66 KB  conda-forge\n",
            "    ca-certificates-2025.10.5  |       hbd8a1cb_0         152 KB  conda-forge\n",
            "    cairo-1.18.4               |       h3394656_0         955 KB  conda-forge\n",
            "    certifi-2025.10.5          |     pyhd8ed1ab_0         156 KB  conda-forge\n",
            "    conda-24.11.3              |  py311h38be061_0         1.1 MB  conda-forge\n",
            "    dav1d-1.2.1                |       hd590300_0         742 KB  conda-forge\n",
            "    dbus-1.16.2                |       h3c4dab8_0         428 KB  conda-forge\n",
            "    ffmpeg-7.1.1               | gpl_h5c0ada0_711        10.1 MB  conda-forge\n",
            "    font-ttf-dejavu-sans-mono-2.37|       hab24e00_0         388 KB  conda-forge\n",
            "    font-ttf-inconsolata-3.000 |       h77eed37_0          94 KB  conda-forge\n",
            "    font-ttf-source-code-pro-2.038|       h77eed37_0         684 KB  conda-forge\n",
            "    font-ttf-ubuntu-0.83       |       h77eed37_3         1.5 MB  conda-forge\n",
            "    fontconfig-2.15.0          |       h7e30c49_1         259 KB  conda-forge\n",
            "    fonts-conda-ecosystem-1    |                0           4 KB  conda-forge\n",
            "    fonts-conda-forge-1        |                0           4 KB  conda-forge\n",
            "    freetype-2.14.1            |       ha770c72_0         169 KB  conda-forge\n",
            "    fribidi-1.0.16             |       hb03c661_0          60 KB  conda-forge\n",
            "    gdk-pixbuf-2.44.3          |       h2b0a6b4_0         559 KB  conda-forge\n",
            "    gettext-0.25.1             |       h3f43e3d_1         529 KB  conda-forge\n",
            "    gettext-tools-0.25.1       |       h3f43e3d_1         3.5 MB  conda-forge\n",
            "    gmp-6.3.0                  |       hac33072_2         449 KB  conda-forge\n",
            "    graphite2-1.3.14           |       hecca717_2          97 KB  conda-forge\n",
            "    harfbuzz-12.1.0            |       h15599e2_0         2.0 MB  conda-forge\n",
            "    icu-75.1                   |       he02047a_0        11.6 MB  conda-forge\n",
            "    intel-gmmlib-22.8.2        |       hb700be7_0         976 KB  conda-forge\n",
            "    intel-media-driver-25.3.4  |       hecca717_0         8.0 MB  conda-forge\n",
            "    lame-3.100                 |    h166bdaf_1003         496 KB  conda-forge\n",
            "    lerc-4.0.0                 |       h0aef613_1         258 KB  conda-forge\n",
            "    level-zero-1.24.3          |       hb700be7_0         596 KB  conda-forge\n",
            "    libabseil-20250512.1       | cxx17_hba17884_0         1.2 MB  conda-forge\n",
            "    libasprintf-0.25.1         |       h3f43e3d_1          52 KB  conda-forge\n",
            "    libasprintf-devel-0.25.1   |       h3f43e3d_1          34 KB  conda-forge\n",
            "    libass-0.17.4              |       h96ad9f0_0         149 KB  conda-forge\n",
            "    libcap-2.76                |       h0b2e76d_0         119 KB  conda-forge\n",
            "    libdeflate-1.24            |       h86f0d12_0          71 KB  conda-forge\n",
            "    libdrm-2.4.125             |       hb03c661_1         304 KB  conda-forge\n",
            "    libegl-1.7.0               |       ha4b6fd6_2          44 KB  conda-forge\n",
            "    libexpat-2.7.1             |       hecca717_0          73 KB  conda-forge\n",
            "    libffi-3.4.6               |       h2dba641_1          56 KB  conda-forge\n",
            "    libflac-1.4.3              |       h59595ed_0         385 KB  conda-forge\n",
            "    libfreetype-2.14.1         |       ha770c72_0           7 KB  conda-forge\n",
            "    libfreetype6-2.14.1        |       h73754d4_0         378 KB  conda-forge\n",
            "    libgcrypt-lib-1.11.1       |       hb9d3cd8_0         577 KB  conda-forge\n",
            "    libgettextpo-0.25.1        |       h3f43e3d_1         184 KB  conda-forge\n",
            "    libgettextpo-devel-0.25.1  |       h3f43e3d_1          37 KB  conda-forge\n",
            "    libgl-1.7.0                |       ha4b6fd6_2         132 KB  conda-forge\n",
            "    libglib-2.86.0             |       h1fed272_0         3.8 MB  conda-forge\n",
            "    libglvnd-1.7.0             |       ha4b6fd6_2         129 KB  conda-forge\n",
            "    libglx-1.7.0               |       ha4b6fd6_2          74 KB  conda-forge\n",
            "    libgpg-error-1.55          |       h3f2d84a_0         305 KB  conda-forge\n",
            "    libhwloc-2.12.1            |default_h7f8ec31_1002         2.3 MB  conda-forge\n",
            "    libiconv-1.18              |       h3b78370_2         772 KB  conda-forge\n",
            "    libjpeg-turbo-3.1.0        |       hb9d3cd8_0         614 KB  conda-forge\n",
            "    liblzma-5.8.1              |       hb9d3cd8_2         110 KB  conda-forge\n",
            "    libogg-1.3.5               |       hd0c01bc_1         213 KB  conda-forge\n",
            "    libopenvino-2025.2.0       |       hb617929_1         6.0 MB  conda-forge\n",
            "    libopenvino-auto-batch-plugin-2025.2.0|       hed573e4_1         112 KB  conda-forge\n",
            "    libopenvino-auto-plugin-2025.2.0|       hed573e4_1         245 KB  conda-forge\n",
            "    libopenvino-hetero-plugin-2025.2.0|       hd41364c_1         190 KB  conda-forge\n",
            "    libopenvino-intel-cpu-plugin-2025.2.0|       hb617929_1        11.8 MB  conda-forge\n",
            "    libopenvino-intel-gpu-plugin-2025.2.0|       hb617929_1        10.3 MB  conda-forge\n",
            "    libopenvino-intel-npu-plugin-2025.2.0|       hb617929_1         1.2 MB  conda-forge\n",
            "    libopenvino-ir-frontend-2025.2.0|       hd41364c_1         200 KB  conda-forge\n",
            "    libopenvino-onnx-frontend-2025.2.0|       h1862bb8_1         1.6 MB  conda-forge\n",
            "    libopenvino-paddle-frontend-2025.2.0|       h1862bb8_1         727 KB  conda-forge\n",
            "    libopenvino-pytorch-frontend-2025.2.0|       hecca717_1         1.2 MB  conda-forge\n",
            "    libopenvino-tensorflow-frontend-2025.2.0|       h0767aad_1         1.3 MB  conda-forge\n",
            "    libopenvino-tensorflow-lite-frontend-2025.2.0|       hecca717_1         485 KB  conda-forge\n",
            "    libopus-1.5.2              |       hd0c01bc_0         305 KB  conda-forge\n",
            "    libpciaccess-0.18          |       hb9d3cd8_0          28 KB  conda-forge\n",
            "    libpng-1.6.50              |       h421ea60_1         310 KB  conda-forge\n",
            "    libprotobuf-6.31.1         |       h49aed37_2         4.4 MB  conda-forge\n",
            "    librsvg-2.60.0             |       h61e6d4b_0         3.3 MB  conda-forge\n",
            "    libsndfile-1.2.2           |       hc60ed4a_1         346 KB  conda-forge\n",
            "    libsystemd0-257.9          |       h996ca69_0         481 KB  conda-forge\n",
            "    libtiff-4.7.1              |       h8261f1e_0         427 KB  conda-forge\n",
            "    libudev1-257.9             |       h085a93f_0         141 KB  conda-forge\n",
            "    libunwind-1.8.3            |       h65a8314_0          74 KB  conda-forge\n",
            "    liburing-2.12              |       hb700be7_0         125 KB  conda-forge\n",
            "    libusb-1.0.29              |       h73b1eb8_0          87 KB  conda-forge\n",
            "    libva-2.22.0               |       h4f16b4b_2         212 KB  conda-forge\n",
            "    libvorbis-1.3.7            |       h54a6638_2         279 KB  conda-forge\n",
            "    libvpl-2.15.0              |       h54a6638_1         281 KB  conda-forge\n",
            "    libvpx-1.14.1              |       hac33072_0         999 KB  conda-forge\n",
            "    libvulkan-loader-1.4.328.1 |       h5279c79_0         193 KB  conda-forge\n",
            "    libwebp-base-1.6.0         |       hd42ef1d_0         419 KB  conda-forge\n",
            "    libxcb-1.17.0              |       h8a09558_0         387 KB  conda-forge\n",
            "    libxkbcommon-1.12.1        |       hca5e8e5_0         809 KB  conda-forge\n",
            "    libxml2-2.15.0             |       h26afc86_1          44 KB  conda-forge\n",
            "    libxml2-16-2.15.0          |       ha9997c6_1         543 KB  conda-forge\n",
            "    mpg123-1.32.9              |       hc50e24c_0         480 KB  conda-forge\n",
            "    ocl-icd-2.3.3              |       hb9d3cd8_0         104 KB  conda-forge\n",
            "    opencl-headers-2025.06.13  |       h5888daf_0          54 KB  conda-forge\n",
            "    openh264-2.6.0             |       hc22cd8d_0         714 KB  conda-forge\n",
            "    openssl-3.5.4              |       h26f9b46_0         3.0 MB  conda-forge\n",
            "    pango-1.56.4               |       hadf4263_0         445 KB  conda-forge\n",
            "    pcre2-10.46                |       h1321c63_0         1.2 MB  conda-forge\n",
            "    pixman-0.46.4              |       h54a6638_1         440 KB  conda-forge\n",
            "    pthread-stubs-0.4          |    hb9d3cd8_1002           8 KB  conda-forge\n",
            "    pugixml-1.15               |       h3f63f65_0         116 KB  conda-forge\n",
            "    pulseaudio-client-17.0     |       h9a8bead_2         744 KB  conda-forge\n",
            "    sdl2-2.32.56               |       h54a6638_0         575 KB  conda-forge\n",
            "    sdl3-3.2.24                |       h68140b3_0         1.8 MB  conda-forge\n",
            "    snappy-1.2.2               |       h03e3b7b_0          45 KB  conda-forge\n",
            "    svt-av1-3.1.2              |       hecca717_0         2.6 MB  conda-forge\n",
            "    tbb-2022.2.0               |       hb60516a_1         179 KB  conda-forge\n",
            "    wayland-1.24.0             |       h3e06ad9_0         323 KB  conda-forge\n",
            "    wayland-protocols-1.45     |       hd8ed1ab_0         135 KB  conda-forge\n",
            "    x264-1!164.3095            |       h166bdaf_2         877 KB  conda-forge\n",
            "    x265-3.5                   |       h924138e_3         3.2 MB  conda-forge\n",
            "    xkeyboard-config-2.46      |       hb03c661_0         388 KB  conda-forge\n",
            "    xorg-libice-1.1.2          |       hb9d3cd8_0          57 KB  conda-forge\n",
            "    xorg-libsm-1.2.6           |       he73a12e_0          27 KB  conda-forge\n",
            "    xorg-libx11-1.8.12         |       h4f16b4b_0         816 KB  conda-forge\n",
            "    xorg-libxau-1.0.12         |       hb9d3cd8_0          14 KB  conda-forge\n",
            "    xorg-libxcursor-1.2.3      |       hb9d3cd8_0          32 KB  conda-forge\n",
            "    xorg-libxdmcp-1.1.5        |       hb9d3cd8_0          19 KB  conda-forge\n",
            "    xorg-libxext-1.3.6         |       hb9d3cd8_0          49 KB  conda-forge\n",
            "    xorg-libxfixes-6.0.2       |       hb03c661_0          20 KB  conda-forge\n",
            "    xorg-libxrandr-1.5.4       |       hb9d3cd8_0          29 KB  conda-forge\n",
            "    xorg-libxrender-0.9.12     |       hb9d3cd8_0          32 KB  conda-forge\n",
            "    xorg-libxscrnsaver-1.2.4   |       hb9d3cd8_0          14 KB  conda-forge\n",
            "    zstandard-0.25.0           |  py311haee01d2_0         456 KB  conda-forge\n",
            "    zstd-1.5.7                 |       hb8e6e7a_2         554 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       129.6 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  alsa-lib           conda-forge/linux-64::alsa-lib-1.2.14-hb9d3cd8_0 \n",
            "  aom                conda-forge/linux-64::aom-3.9.1-hac33072_0 \n",
            "  attr               conda-forge/linux-64::attr-2.5.2-h39aace5_0 \n",
            "  cairo              conda-forge/linux-64::cairo-1.18.4-h3394656_0 \n",
            "  dav1d              conda-forge/linux-64::dav1d-1.2.1-hd590300_0 \n",
            "  dbus               conda-forge/linux-64::dbus-1.16.2-h3c4dab8_0 \n",
            "  ffmpeg             conda-forge/linux-64::ffmpeg-7.1.1-gpl_h5c0ada0_711 \n",
            "  font-ttf-dejavu-s~ conda-forge/noarch::font-ttf-dejavu-sans-mono-2.37-hab24e00_0 \n",
            "  font-ttf-inconsol~ conda-forge/noarch::font-ttf-inconsolata-3.000-h77eed37_0 \n",
            "  font-ttf-source-c~ conda-forge/noarch::font-ttf-source-code-pro-2.038-h77eed37_0 \n",
            "  font-ttf-ubuntu    conda-forge/noarch::font-ttf-ubuntu-0.83-h77eed37_3 \n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.15.0-h7e30c49_1 \n",
            "  fonts-conda-ecosy~ conda-forge/noarch::fonts-conda-ecosystem-1-0 \n",
            "  fonts-conda-forge  conda-forge/noarch::fonts-conda-forge-1-0 \n",
            "  freetype           conda-forge/linux-64::freetype-2.14.1-ha770c72_0 \n",
            "  fribidi            conda-forge/linux-64::fribidi-1.0.16-hb03c661_0 \n",
            "  gdk-pixbuf         conda-forge/linux-64::gdk-pixbuf-2.44.3-h2b0a6b4_0 \n",
            "  gettext            conda-forge/linux-64::gettext-0.25.1-h3f43e3d_1 \n",
            "  gettext-tools      conda-forge/linux-64::gettext-tools-0.25.1-h3f43e3d_1 \n",
            "  gmp                conda-forge/linux-64::gmp-6.3.0-hac33072_2 \n",
            "  graphite2          conda-forge/linux-64::graphite2-1.3.14-hecca717_2 \n",
            "  harfbuzz           conda-forge/linux-64::harfbuzz-12.1.0-h15599e2_0 \n",
            "  icu                conda-forge/linux-64::icu-75.1-he02047a_0 \n",
            "  intel-gmmlib       conda-forge/linux-64::intel-gmmlib-22.8.2-hb700be7_0 \n",
            "  intel-media-driver conda-forge/linux-64::intel-media-driver-25.3.4-hecca717_0 \n",
            "  lame               conda-forge/linux-64::lame-3.100-h166bdaf_1003 \n",
            "  lerc               conda-forge/linux-64::lerc-4.0.0-h0aef613_1 \n",
            "  level-zero         conda-forge/linux-64::level-zero-1.24.3-hb700be7_0 \n",
            "  libabseil          conda-forge/linux-64::libabseil-20250512.1-cxx17_hba17884_0 \n",
            "  libasprintf        conda-forge/linux-64::libasprintf-0.25.1-h3f43e3d_1 \n",
            "  libasprintf-devel  conda-forge/linux-64::libasprintf-devel-0.25.1-h3f43e3d_1 \n",
            "  libass             conda-forge/linux-64::libass-0.17.4-h96ad9f0_0 \n",
            "  libcap             conda-forge/linux-64::libcap-2.76-h0b2e76d_0 \n",
            "  libdeflate         conda-forge/linux-64::libdeflate-1.24-h86f0d12_0 \n",
            "  libdrm             conda-forge/linux-64::libdrm-2.4.125-hb03c661_1 \n",
            "  libegl             conda-forge/linux-64::libegl-1.7.0-ha4b6fd6_2 \n",
            "  libflac            conda-forge/linux-64::libflac-1.4.3-h59595ed_0 \n",
            "  libfreetype        conda-forge/linux-64::libfreetype-2.14.1-ha770c72_0 \n",
            "  libfreetype6       conda-forge/linux-64::libfreetype6-2.14.1-h73754d4_0 \n",
            "  libgcrypt-lib      conda-forge/linux-64::libgcrypt-lib-1.11.1-hb9d3cd8_0 \n",
            "  libgettextpo       conda-forge/linux-64::libgettextpo-0.25.1-h3f43e3d_1 \n",
            "  libgettextpo-devel conda-forge/linux-64::libgettextpo-devel-0.25.1-h3f43e3d_1 \n",
            "  libgl              conda-forge/linux-64::libgl-1.7.0-ha4b6fd6_2 \n",
            "  libglib            conda-forge/linux-64::libglib-2.86.0-h1fed272_0 \n",
            "  libglvnd           conda-forge/linux-64::libglvnd-1.7.0-ha4b6fd6_2 \n",
            "  libglx             conda-forge/linux-64::libglx-1.7.0-ha4b6fd6_2 \n",
            "  libgpg-error       conda-forge/linux-64::libgpg-error-1.55-h3f2d84a_0 \n",
            "  libhwloc           conda-forge/linux-64::libhwloc-2.12.1-default_h7f8ec31_1002 \n",
            "  libjpeg-turbo      conda-forge/linux-64::libjpeg-turbo-3.1.0-hb9d3cd8_0 \n",
            "  libogg             conda-forge/linux-64::libogg-1.3.5-hd0c01bc_1 \n",
            "  libopenvino        conda-forge/linux-64::libopenvino-2025.2.0-hb617929_1 \n",
            "  libopenvino-auto-~ conda-forge/linux-64::libopenvino-auto-batch-plugin-2025.2.0-hed573e4_1 \n",
            "  libopenvino-auto-~ conda-forge/linux-64::libopenvino-auto-plugin-2025.2.0-hed573e4_1 \n",
            "  libopenvino-heter~ conda-forge/linux-64::libopenvino-hetero-plugin-2025.2.0-hd41364c_1 \n",
            "  libopenvino-intel~ conda-forge/linux-64::libopenvino-intel-cpu-plugin-2025.2.0-hb617929_1 \n",
            "  libopenvino-intel~ conda-forge/linux-64::libopenvino-intel-gpu-plugin-2025.2.0-hb617929_1 \n",
            "  libopenvino-intel~ conda-forge/linux-64::libopenvino-intel-npu-plugin-2025.2.0-hb617929_1 \n",
            "  libopenvino-ir-fr~ conda-forge/linux-64::libopenvino-ir-frontend-2025.2.0-hd41364c_1 \n",
            "  libopenvino-onnx-~ conda-forge/linux-64::libopenvino-onnx-frontend-2025.2.0-h1862bb8_1 \n",
            "  libopenvino-paddl~ conda-forge/linux-64::libopenvino-paddle-frontend-2025.2.0-h1862bb8_1 \n",
            "  libopenvino-pytor~ conda-forge/linux-64::libopenvino-pytorch-frontend-2025.2.0-hecca717_1 \n",
            "  libopenvino-tenso~ conda-forge/linux-64::libopenvino-tensorflow-frontend-2025.2.0-h0767aad_1 \n",
            "  libopenvino-tenso~ conda-forge/linux-64::libopenvino-tensorflow-lite-frontend-2025.2.0-hecca717_1 \n",
            "  libopus            conda-forge/linux-64::libopus-1.5.2-hd0c01bc_0 \n",
            "  libpciaccess       conda-forge/linux-64::libpciaccess-0.18-hb9d3cd8_0 \n",
            "  libpng             conda-forge/linux-64::libpng-1.6.50-h421ea60_1 \n",
            "  libprotobuf        conda-forge/linux-64::libprotobuf-6.31.1-h49aed37_2 \n",
            "  librsvg            conda-forge/linux-64::librsvg-2.60.0-h61e6d4b_0 \n",
            "  libsndfile         conda-forge/linux-64::libsndfile-1.2.2-hc60ed4a_1 \n",
            "  libsystemd0        conda-forge/linux-64::libsystemd0-257.9-h996ca69_0 \n",
            "  libtiff            conda-forge/linux-64::libtiff-4.7.1-h8261f1e_0 \n",
            "  libudev1           conda-forge/linux-64::libudev1-257.9-h085a93f_0 \n",
            "  libunwind          conda-forge/linux-64::libunwind-1.8.3-h65a8314_0 \n",
            "  liburing           conda-forge/linux-64::liburing-2.12-hb700be7_0 \n",
            "  libusb             conda-forge/linux-64::libusb-1.0.29-h73b1eb8_0 \n",
            "  libva              conda-forge/linux-64::libva-2.22.0-h4f16b4b_2 \n",
            "  libvorbis          conda-forge/linux-64::libvorbis-1.3.7-h54a6638_2 \n",
            "  libvpl             conda-forge/linux-64::libvpl-2.15.0-h54a6638_1 \n",
            "  libvpx             conda-forge/linux-64::libvpx-1.14.1-hac33072_0 \n",
            "  libvulkan-loader   conda-forge/linux-64::libvulkan-loader-1.4.328.1-h5279c79_0 \n",
            "  libwebp-base       conda-forge/linux-64::libwebp-base-1.6.0-hd42ef1d_0 \n",
            "  libxcb             conda-forge/linux-64::libxcb-1.17.0-h8a09558_0 \n",
            "  libxkbcommon       conda-forge/linux-64::libxkbcommon-1.12.1-hca5e8e5_0 \n",
            "  libxml2-16         conda-forge/linux-64::libxml2-16-2.15.0-ha9997c6_1 \n",
            "  mpg123             conda-forge/linux-64::mpg123-1.32.9-hc50e24c_0 \n",
            "  ocl-icd            conda-forge/linux-64::ocl-icd-2.3.3-hb9d3cd8_0 \n",
            "  opencl-headers     conda-forge/linux-64::opencl-headers-2025.06.13-h5888daf_0 \n",
            "  openh264           conda-forge/linux-64::openh264-2.6.0-hc22cd8d_0 \n",
            "  pango              conda-forge/linux-64::pango-1.56.4-hadf4263_0 \n",
            "  pcre2              conda-forge/linux-64::pcre2-10.46-h1321c63_0 \n",
            "  pixman             conda-forge/linux-64::pixman-0.46.4-h54a6638_1 \n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-hb9d3cd8_1002 \n",
            "  pugixml            conda-forge/linux-64::pugixml-1.15-h3f63f65_0 \n",
            "  pulseaudio-client  conda-forge/linux-64::pulseaudio-client-17.0-h9a8bead_2 \n",
            "  sdl2               conda-forge/linux-64::sdl2-2.32.56-h54a6638_0 \n",
            "  sdl3               conda-forge/linux-64::sdl3-3.2.24-h68140b3_0 \n",
            "  snappy             conda-forge/linux-64::snappy-1.2.2-h03e3b7b_0 \n",
            "  svt-av1            conda-forge/linux-64::svt-av1-3.1.2-hecca717_0 \n",
            "  tbb                conda-forge/linux-64::tbb-2022.2.0-hb60516a_1 \n",
            "  wayland            conda-forge/linux-64::wayland-1.24.0-h3e06ad9_0 \n",
            "  wayland-protocols  conda-forge/noarch::wayland-protocols-1.45-hd8ed1ab_0 \n",
            "  x264               conda-forge/linux-64::x264-1!164.3095-h166bdaf_2 \n",
            "  x265               conda-forge/linux-64::x265-3.5-h924138e_3 \n",
            "  xkeyboard-config   conda-forge/linux-64::xkeyboard-config-2.46-hb03c661_0 \n",
            "  xorg-libice        conda-forge/linux-64::xorg-libice-1.1.2-hb9d3cd8_0 \n",
            "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.6-he73a12e_0 \n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.8.12-h4f16b4b_0 \n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.12-hb9d3cd8_0 \n",
            "  xorg-libxcursor    conda-forge/linux-64::xorg-libxcursor-1.2.3-hb9d3cd8_0 \n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.5-hb9d3cd8_0 \n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.6-hb9d3cd8_0 \n",
            "  xorg-libxfixes     conda-forge/linux-64::xorg-libxfixes-6.0.2-hb03c661_0 \n",
            "  xorg-libxrandr     conda-forge/linux-64::xorg-libxrandr-1.5.4-hb9d3cd8_0 \n",
            "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.12-hb9d3cd8_0 \n",
            "  xorg-libxscrnsaver conda-forge/linux-64::xorg-libxscrnsaver-1.2.4-hb9d3cd8_0 \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates    conda-forge/linux-64::ca-certificates~ --> conda-forge/noarch::ca-certificates-2025.10.5-hbd8a1cb_0 \n",
            "  certifi                           2024.12.14-pyhd8ed1ab_0 --> 2025.10.5-pyhd8ed1ab_0 \n",
            "  conda                             24.11.2-py311h38be061_1 --> 24.11.3-py311h38be061_0 \n",
            "  libexpat                                 2.6.4-h5888daf_0 --> 2.7.1-hecca717_0 \n",
            "  libffi                                   3.4.2-h7f98852_5 --> 3.4.6-h2dba641_1 \n",
            "  libiconv                                  1.17-hd590300_2 --> 1.18-h3b78370_2 \n",
            "  liblzma                                  5.6.3-hb9d3cd8_1 --> 5.8.1-hb9d3cd8_2 \n",
            "  libxml2                                 2.13.5-h0d44e9d_1 --> 2.15.0-h26afc86_1 \n",
            "  openssl                                  3.4.0-h7b32b05_1 --> 3.5.4-h26f9b46_0 \n",
            "  zstandard                          0.23.0-py311hbc35293_1 --> 0.25.0-py311haee01d2_0 \n",
            "  zstd                                     1.5.6-ha6fb4c9_0 --> 1.5.7-hb8e6e7a_2 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "libopenvino-intel-cp | 11.8 MB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "icu-75.1             | 11.6 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "libopenvino-intel-gp | 10.3 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "ffmpeg-7.1.1         | 10.1 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "intel-media-driver-2 | 8.0 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenvino-2025.2.0 | 6.0 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libprotobuf-6.31.1   | 4.4 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libglib-2.86.0       | 3.8 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gettext-tools-0.25.1 | 3.5 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "librsvg-2.60.0       | 3.3 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "x265-3.5             | 3.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.5.4        | 3.0 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "svt-av1-3.1.2        | 2.6 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "aom-3.9.1            | 2.6 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libhwloc-2.12.1      | 2.3 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "harfbuzz-12.1.0      | 2.0 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sdl3-3.2.24          | 1.8 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenvino-onnx-fro | 1.6 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "font-ttf-ubuntu-0.83 | 1.5 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenvino-intel-cp | 11.8 MB   | :   2% 0.02117909546751328/1 [00:00<00:04,  4.75s/it]\n",
            "icu-75.1             | 11.6 MB   | :   1% 0.00540315798160852/1 [00:00<00:18, 18.73s/it]\u001b[A\n",
            "\n",
            "libopenvino-intel-gp | 10.3 MB   | :   1% 0.009089194376948596/1 [00:00<00:10, 11.08s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "ffmpeg-7.1.1         | 10.1 MB   | :   2% 0.020202455174237546/1 [00:00<00:04,  4.98s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libopenvino-intel-cp | 11.8 MB   | :  40% 0.40372650734947185/1 [00:00<00:00,  2.33it/s]\n",
            "\n",
            "libopenvino-intel-gp | 10.3 MB   | :  38% 0.381746163831841/1 [00:00<00:00,  2.22it/s]   \u001b[A\u001b[A\n",
            "icu-75.1             | 11.6 MB   | :  33% 0.3295926368781197/1 [00:00<00:00,  1.91it/s] \u001b[A\n",
            "\n",
            "\n",
            "ffmpeg-7.1.1         | 10.1 MB   | :  44% 0.43512980375280863/1 [00:00<00:00,  2.52it/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libopenvino-intel-cp | 11.8 MB   | :  75% 0.753181582563441/1 [00:00<00:00,  2.86it/s]  \n",
            "icu-75.1             | 11.6 MB   | :  64% 0.6416250103160117/1 [00:00<00:00,  2.46it/s]\u001b[A\n",
            "\n",
            "libopenvino-intel-gp | 10.3 MB   | :  72% 0.7150166243199562/1 [00:00<00:00,  2.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "ffmpeg-7.1.1         | 10.1 MB   | :  83% 0.8298546971571422/1 [00:00<00:00,  3.17it/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "intel-media-driver-2 | 8.0 MB    | :  90% 0.8984876451254123/1 [00:00<00:00,  3.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "intel-media-driver-2 | 8.0 MB    | : 100% 1.0/1 [00:00<00:00,  3.35it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "ffmpeg-7.1.1         | 10.1 MB   | : 100% 1.0/1 [00:00<00:00,  3.17it/s]               \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenvino-intel-cp | 11.8 MB   | : 100% 1.0/1 [00:00<00:00,  2.86it/s]              \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libprotobuf-6.31.1   | 4.4 MB    | :   0% 0.003526568509361851/1 [00:00<02:28, 149.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libopenvino-intel-gp | 10.3 MB   | : 100% 1.0/1 [00:00<00:00,  1.69it/s]               \u001b[A\u001b[A\n",
            "\n",
            "libopenvino-intel-gp | 10.3 MB   | : 100% 1.0/1 [00:00<00:00,  1.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libglib-2.86.0       | 3.8 MB    | :   0% 0.004118029398266024/1 [00:00<02:21, 142.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenvino-2025.2.0 | 6.0 MB    | :  55% 0.5457160879077871/1 [00:00<00:00,  1.23it/s]    \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "icu-75.1             | 11.6 MB   | : 100% 1.0/1 [00:00<00:00,  1.61it/s]               \u001b[A\n",
            "icu-75.1             | 11.6 MB   | : 100% 1.0/1 [00:00<00:00,  1.61it/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gettext-tools-0.25.1 | 3.5 MB    | :   0% 0.00449603098485416/1 [00:00<02:14, 134.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libprotobuf-6.31.1   | 4.4 MB    | :  70% 0.6982605648536465/1 [00:00<00:00,  1.47it/s]   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "librsvg-2.60.0       | 3.3 MB    | :   0% 0.004787875546796486/1 [00:00<02:13, 133.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libglib-2.86.0       | 3.8 MB    | :  82% 0.8153698208566728/1 [00:00<00:00,  1.59it/s]   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gettext-tools-0.25.1 | 3.5 MB    | :  48% 0.48107531537939513/1 [00:00<00:00,  1.09s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenvino-2025.2.0 | 6.0 MB    | :  87% 0.8657995625460085/1 [00:00<00:00,  1.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "librsvg-2.60.0       | 3.3 MB    | :  90% 0.8953327272509429/1 [00:00<00:00,  1.63it/s]   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libprotobuf-6.31.1   | 4.4 MB    | : 100% 1.0/1 [00:00<00:00,  1.47it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libglib-2.86.0       | 3.8 MB    | : 100% 1.0/1 [00:00<00:00,  1.59it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "x265-3.5             | 3.2 MB    | :   0% 0.004880274801411181/1 [00:00<02:44, 165.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.5.4        | 3.0 MB    | :   1% 0.005251914974368706/1 [00:00<02:39, 159.87s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenvino-2025.2.0 | 6.0 MB    | : 100% 1.0/1 [00:00<00:00,  1.63it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "librsvg-2.60.0       | 3.3 MB    | : 100% 1.0/1 [00:00<00:00,  1.63it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gettext-tools-0.25.1 | 3.5 MB    | : 100% 1.0/1 [00:00<00:00,  1.67it/s]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gettext-tools-0.25.1 | 3.5 MB    | : 100% 1.0/1 [00:00<00:00,  1.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "aom-3.9.1            | 2.6 MB    | :   1% 0.006053807351178468/1 [00:00<02:26, 147.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "svt-av1-3.1.2        | 2.6 MB    | :   1% 0.005976944403910696/1 [00:00<02:30, 151.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libhwloc-2.12.1      | 2.3 MB    | :   1% 0.006685595039993602/1 [00:00<02:14, 135.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "x265-3.5             | 3.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.44it/s]                  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "x265-3.5             | 3.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.5.4        | 3.0 MB    | : 100% 1.0/1 [00:00<00:00,  1.39it/s]                  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.5.4        | 3.0 MB    | : 100% 1.0/1 [00:00<00:00,  1.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libhwloc-2.12.1      | 2.3 MB    | : 100% 1.0/1 [00:01<00:00, 135.62s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "harfbuzz-12.1.0      | 2.0 MB    | :   1% 0.007959526120595759/1 [00:01<02:05, 126.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "aom-3.9.1            | 2.6 MB    | : 100% 1.0/1 [00:01<00:00,  1.33it/s]                  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "aom-3.9.1            | 2.6 MB    | : 100% 1.0/1 [00:01<00:00,  1.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sdl3-3.2.24          | 1.8 MB    | :   1% 0.00846124965592605/1 [00:01<02:01, 122.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "svt-av1-3.1.2        | 2.6 MB    | :  72% 0.7172333284692836/1 [00:01<00:00,  1.09s/it]   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenvino-onnx-fro | 1.6 MB    | :   1% 0.00950070832002032/1 [00:01<01:50, 111.88s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "font-ttf-ubuntu-0.83 | 1.5 MB    | :   1% 0.010110434778315882/1 [00:01<01:45, 106.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "harfbuzz-12.1.0      | 2.0 MB    | : 100% 1.0/1 [00:01<00:00, 126.14s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sdl3-3.2.24          | 1.8 MB    | : 100% 1.0/1 [00:01<00:00,  1.20it/s]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sdl3-3.2.24          | 1.8 MB    | : 100% 1.0/1 [00:01<00:00,  1.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "svt-av1-3.1.2        | 2.6 MB    | : 100% 1.0/1 [00:01<00:00,  1.09s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "font-ttf-ubuntu-0.83 | 1.5 MB    | : 100% 1.0/1 [00:01<00:00, 106.57s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenvino-onnx-fro | 1.6 MB    | : 100% 1.0/1 [00:01<00:00,  1.17it/s]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenvino-onnx-fro | 1.6 MB    | : 100% 1.0/1 [00:01<00:00,  1.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "intel-media-driver-2 | 8.0 MB    | : 100% 1.0/1 [00:01<00:00,  3.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libopenvino-intel-cp | 11.8 MB   | : 100% 1.0/1 [00:02<00:00,  2.86it/s]\n",
            "\n",
            "libopenvino-intel-gp | 10.3 MB   | : 100% 1.0/1 [00:02<00:00,  1.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libprotobuf-6.31.1   | 4.4 MB    | : 100% 1.0/1 [00:02<00:00,  1.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "icu-75.1             | 11.6 MB   | : 100% 1.0/1 [00:02<00:00,  1.61it/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libglib-2.86.0       | 3.8 MB    | : 100% 1.0/1 [00:02<00:00,  1.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenvino-2025.2.0 | 6.0 MB    | : 100% 1.0/1 [00:02<00:00,  1.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "librsvg-2.60.0       | 3.3 MB    | : 100% 1.0/1 [00:02<00:00,  1.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gettext-tools-0.25.1 | 3.5 MB    | : 100% 1.0/1 [00:03<00:00,  1.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.5.4        | 3.0 MB    | : 100% 1.0/1 [00:03<00:00,  1.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libhwloc-2.12.1      | 2.3 MB    | : 100% 1.0/1 [00:03<00:00,  3.28s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libhwloc-2.12.1      | 2.3 MB    | : 100% 1.0/1 [00:03<00:00,  3.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "aom-3.9.1            | 2.6 MB    | : 100% 1.0/1 [00:03<00:00,  1.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "harfbuzz-12.1.0      | 2.0 MB    | : 100% 1.0/1 [00:03<00:00,  3.40s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "harfbuzz-12.1.0      | 2.0 MB    | : 100% 1.0/1 [00:03<00:00,  3.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sdl3-3.2.24          | 1.8 MB    | : 100% 1.0/1 [00:03<00:00,  1.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "svt-av1-3.1.2        | 2.6 MB    | : 100% 1.0/1 [00:03<00:00,  1.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "font-ttf-ubuntu-0.83 | 1.5 MB    | : 100% 1.0/1 [00:03<00:00,  3.56s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "font-ttf-ubuntu-0.83 | 1.5 MB    | : 100% 1.0/1 [00:03<00:00,  3.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenvino-onnx-fro | 1.6 MB    | : 100% 1.0/1 [00:03<00:00,  1.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "x265-3.5             | 3.2 MB    | : 100% 1.0/1 [00:04<00:00,  1.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \n",
            "\b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \n",
            "\b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Obtaining file:///content/lerobot\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting datasets<4.2.0,>=4.0.0 (from lerobot==0.3.4)\n",
            "  Downloading datasets-4.1.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting diffusers<0.36.0,>=0.27.2 (from lerobot==0.3.4)\n",
            "  Downloading diffusers-0.35.2-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting huggingface-hub<0.36.0,>=0.34.2 (from huggingface-hub[cli,hf-transfer]<0.36.0,>=0.34.2->lerobot==0.3.4)\n",
            "  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting accelerate<2.0.0,>=1.10.0 (from lerobot==0.3.4)\n",
            "  Downloading accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting setuptools<81.0.0,>=71.0.0 (from lerobot==0.3.4)\n",
            "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting cmake<4.2.0,>=3.29.0.1 (from lerobot==0.3.4)\n",
            "  Downloading cmake-4.1.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting einops<0.9.0,>=0.8.0 (from lerobot==0.3.4)\n",
            "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting opencv-python-headless<4.13.0,>=4.9.0 (from lerobot==0.3.4)\n",
            "  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
            "Collecting av<16.0.0,>=15.0.0 (from lerobot==0.3.4)\n",
            "  Downloading av-15.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting jsonlines<5.0.0,>=4.0.0 (from lerobot==0.3.4)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: packaging<26.0,>=24.2 in /usr/local/lib/python3.11/site-packages (from lerobot==0.3.4) (24.2)\n",
            "Collecting pynput<1.9.0,>=1.7.7 (from lerobot==0.3.4)\n",
            "  Downloading pynput-1.8.1-py2.py3-none-any.whl.metadata (32 kB)\n",
            "Collecting pyserial<4.0,>=3.5 (from lerobot==0.3.4)\n",
            "  Downloading pyserial-3.5-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting wandb<0.22.0,>=0.20.0 (from lerobot==0.3.4)\n",
            "  Downloading wandb-0.21.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting torch<2.8.0,>=2.2.1 (from lerobot==0.3.4)\n",
            "  Downloading torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting torchcodec<0.6.0,>=0.2.1 (from lerobot==0.3.4)\n",
            "  Downloading torchcodec-0.5-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Collecting torchvision<0.23.0,>=0.21.0 (from lerobot==0.3.4)\n",
            "  Downloading torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting draccus==0.10.0 (from lerobot==0.3.4)\n",
            "  Downloading draccus-0.10.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting gymnasium>=1.0.0 (from lerobot==0.3.4)\n",
            "  Downloading gymnasium-1.2.1-py3-none-any.whl.metadata (10.0 kB)\n",
            "Collecting rerun-sdk<0.27.0,>=0.24.0 (from lerobot==0.3.4)\n",
            "  Downloading rerun_sdk-0.26.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting deepdiff<9.0.0,>=7.0.1 (from lerobot==0.3.4)\n",
            "  Downloading deepdiff-8.6.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting imageio<3.0.0,>=2.34.0 (from imageio[ffmpeg]<3.0.0,>=2.34.0->lerobot==0.3.4)\n",
            "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting termcolor<4.0.0,>=2.4.0 (from lerobot==0.3.4)\n",
            "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting mergedeep~=1.3 (from draccus==0.10.0->lerobot==0.3.4)\n",
            "  Downloading mergedeep-1.3.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting pyyaml~=6.0 (from draccus==0.10.0->lerobot==0.3.4)\n",
            "  Downloading pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting pyyaml-include~=1.4 (from draccus==0.10.0->lerobot==0.3.4)\n",
            "  Downloading pyyaml_include-1.4.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting toml~=0.10 (from draccus==0.10.0->lerobot==0.3.4)\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect~=0.9.0 (from draccus==0.10.0->lerobot==0.3.4)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting numpy<3.0.0,>=1.17 (from accelerate<2.0.0,>=1.10.0->lerobot==0.3.4)\n",
            "  Downloading numpy-2.3.4-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Collecting psutil (from accelerate<2.0.0,>=1.10.0->lerobot==0.3.4)\n",
            "  Downloading psutil-7.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (23 kB)\n",
            "Collecting safetensors>=0.4.3 (from accelerate<2.0.0,>=1.10.0->lerobot==0.3.4)\n",
            "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting filelock (from datasets<4.2.0,>=4.0.0->lerobot==0.3.4)\n",
            "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting pyarrow>=21.0.0 (from datasets<4.2.0,>=4.0.0->lerobot==0.3.4)\n",
            "  Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.4.1,>=0.3.0 (from datasets<4.2.0,>=4.0.0->lerobot==0.3.4)\n",
            "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pandas (from datasets<4.2.0,>=4.0.0->lerobot==0.3.4)\n",
            "  Downloading pandas-2.3.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/site-packages (from datasets<4.2.0,>=4.0.0->lerobot==0.3.4) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/site-packages (from datasets<4.2.0,>=4.0.0->lerobot==0.3.4) (4.67.1)\n",
            "Collecting xxhash (from datasets<4.2.0,>=4.0.0->lerobot==0.3.4)\n",
            "  Downloading xxhash-3.6.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets<4.2.0,>=4.0.0->lerobot==0.3.4)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.9.0,>=2023.1.0 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets<4.2.0,>=4.0.0->lerobot==0.3.4)\n",
            "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting orderly-set<6,>=5.4.1 (from deepdiff<9.0.0,>=7.0.1->lerobot==0.3.4)\n",
            "  Downloading orderly_set-5.5.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting importlib_metadata (from diffusers<0.36.0,>=0.27.2->lerobot==0.3.4)\n",
            "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting regex!=2019.12.17 (from diffusers<0.36.0,>=0.27.2->lerobot==0.3.4)\n",
            "  Downloading regex-2025.9.18-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "Collecting Pillow (from diffusers<0.36.0,>=0.27.2->lerobot==0.3.4)\n",
            "  Downloading pillow-12.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
            "Collecting cloudpickle>=1.2.0 (from gymnasium>=1.0.0->lerobot==0.3.4)\n",
            "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-extensions>=4.3.0 (from gymnasium>=1.0.0->lerobot==0.3.4)\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium>=1.0.0->lerobot==0.3.4)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<0.36.0,>=0.34.2->huggingface-hub[cli,hf-transfer]<0.36.0,>=0.34.2->lerobot==0.3.4)\n",
            "  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Collecting InquirerPy==0.3.4 (from huggingface-hub[cli,hf-transfer]<0.36.0,>=0.34.2->lerobot==0.3.4)\n",
            "  Downloading InquirerPy-0.3.4-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting hf-transfer>=0.1.4 (from huggingface-hub[cli,hf-transfer]<0.36.0,>=0.34.2->lerobot==0.3.4)\n",
            "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting pfzy<0.4.0,>=0.3.1 (from InquirerPy==0.3.4->huggingface-hub[cli,hf-transfer]<0.36.0,>=0.34.2->lerobot==0.3.4)\n",
            "  Downloading pfzy-0.3.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting prompt-toolkit<4.0.0,>=3.0.1 (from InquirerPy==0.3.4->huggingface-hub[cli,hf-transfer]<0.36.0,>=0.34.2->lerobot==0.3.4)\n",
            "  Downloading prompt_toolkit-3.0.52-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting imageio-ffmpeg (from imageio[ffmpeg]<3.0.0,>=2.34.0->lerobot==0.3.4)\n",
            "  Downloading imageio_ffmpeg-0.6.0-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting attrs>=19.2.0 (from jsonlines<5.0.0,>=4.0.0->lerobot==0.3.4)\n",
            "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting numpy<3.0.0,>=1.17 (from accelerate<2.0.0,>=1.10.0->lerobot==0.3.4)\n",
            "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting six (from pynput<1.9.0,>=1.7.7->lerobot==0.3.4)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting evdev>=1.3 (from pynput<1.9.0,>=1.7.7->lerobot==0.3.4)\n",
            "  Downloading evdev-1.9.2.tar.gz (33 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-xlib>=0.17 (from pynput<1.9.0,>=1.7.7->lerobot==0.3.4)\n",
            "  Downloading python_xlib-0.33-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting sympy>=1.13.3 (from torch<2.8.0,>=2.2.1->lerobot==0.3.4)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch<2.8.0,>=2.2.1->lerobot==0.3.4)\n",
            "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch<2.8.0,>=2.2.1->lerobot==0.3.4)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch<2.8.0,>=2.2.1->lerobot==0.3.4)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch<2.8.0,>=2.2.1->lerobot==0.3.4)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch<2.8.0,>=2.2.1->lerobot==0.3.4)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch<2.8.0,>=2.2.1->lerobot==0.3.4)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch<2.8.0,>=2.2.1->lerobot==0.3.4)\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch<2.8.0,>=2.2.1->lerobot==0.3.4)\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch<2.8.0,>=2.2.1->lerobot==0.3.4)\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch<2.8.0,>=2.2.1->lerobot==0.3.4)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch<2.8.0,>=2.2.1->lerobot==0.3.4)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch<2.8.0,>=2.2.1->lerobot==0.3.4)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch<2.8.0,>=2.2.1->lerobot==0.3.4)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch<2.8.0,>=2.2.1->lerobot==0.3.4)\n",
            "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch<2.8.0,>=2.2.1->lerobot==0.3.4)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch<2.8.0,>=2.2.1->lerobot==0.3.4)\n",
            "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.3.1 (from torch<2.8.0,>=2.2.1->lerobot==0.3.4)\n",
            "  Downloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting click>=8.0.1 (from wandb<0.22.0,>=0.20.0->lerobot==0.3.4)\n",
            "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb<0.22.0,>=0.20.0->lerobot==0.3.4)\n",
            "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/site-packages (from wandb<0.22.0,>=0.20.0->lerobot==0.3.4) (4.3.6)\n",
            "Collecting protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 (from wandb<0.22.0,>=0.20.0->lerobot==0.3.4)\n",
            "  Downloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Collecting pydantic<3 (from wandb<0.22.0,>=0.20.0->lerobot==0.3.4)\n",
            "  Downloading pydantic-2.12.3-py3-none-any.whl.metadata (87 kB)\n",
            "Collecting sentry-sdk>=2.0.0 (from wandb<0.22.0,>=0.20.0->lerobot==0.3.4)\n",
            "  Downloading sentry_sdk-2.42.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets<4.2.0,>=4.0.0->lerobot==0.3.4)\n",
            "  Downloading aiohttp-3.13.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb<0.22.0,>=0.20.0->lerobot==0.3.4)\n",
            "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3->wandb<0.22.0,>=0.20.0->lerobot==0.3.4)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.41.4 (from pydantic<3->wandb<0.22.0,>=0.20.0->lerobot==0.3.4)\n",
            "  Downloading pydantic_core-2.41.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspection>=0.4.2 (from pydantic<3->wandb<0.22.0,>=0.20.0->lerobot==0.3.4)\n",
            "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.32.2->datasets<4.2.0,>=4.0.0->lerobot==0.3.4) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests>=2.32.2->datasets<4.2.0,>=4.0.0->lerobot==0.3.4) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.32.2->datasets<4.2.0,>=4.0.0->lerobot==0.3.4) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests>=2.32.2->datasets<4.2.0,>=4.0.0->lerobot==0.3.4) (2025.10.5)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch<2.8.0,>=2.2.1->lerobot==0.3.4)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect~=0.9.0->draccus==0.10.0->lerobot==0.3.4)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting zipp>=3.20 (from importlib_metadata->diffusers<0.36.0,>=0.27.2->lerobot==0.3.4)\n",
            "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch<2.8.0,>=2.2.1->lerobot==0.3.4)\n",
            "  Downloading markupsafe-3.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas->datasets<4.2.0,>=4.0.0->lerobot==0.3.4)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas->datasets<4.2.0,>=4.0.0->lerobot==0.3.4)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->datasets<4.2.0,>=4.0.0->lerobot==0.3.4)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets<4.2.0,>=4.0.0->lerobot==0.3.4)\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets<4.2.0,>=4.0.0->lerobot==0.3.4)\n",
            "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets<4.2.0,>=4.0.0->lerobot==0.3.4)\n",
            "  Downloading frozenlist-1.8.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets<4.2.0,>=4.0.0->lerobot==0.3.4)\n",
            "  Downloading multidict-6.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets<4.2.0,>=4.0.0->lerobot==0.3.4)\n",
            "  Downloading propcache-0.4.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets<4.2.0,>=4.0.0->lerobot==0.3.4)\n",
            "  Downloading yarl-1.22.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb<0.22.0,>=0.20.0->lerobot==0.3.4)\n",
            "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting wcwidth (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface-hub[cli,hf-transfer]<0.36.0,>=0.34.2->lerobot==0.3.4)\n",
            "  Downloading wcwidth-0.2.14-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Downloading draccus-0.10.0-py3-none-any.whl (71 kB)\n",
            "Downloading accelerate-1.10.1-py3-none-any.whl (374 kB)\n",
            "Downloading av-15.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (39.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m39.6/39.6 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cmake-4.1.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (29.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-4.1.1-py3-none-any.whl (503 kB)\n",
            "Downloading deepdiff-8.6.1-py3-none-any.whl (91 kB)\n",
            "Downloading diffusers-0.35.2-py3-none-any.whl (4.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
            "Downloading gymnasium-1.2.1-py3-none-any.whl (951 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m951.1/951.1 kB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n",
            "Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (54.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.0/54.0 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynput-1.8.1-py2.py3-none-any.whl (91 kB)\n",
            "Downloading pyserial-3.5-py2.py3-none-any.whl (90 kB)\n",
            "Downloading rerun_sdk-0.26.0-cp39-abi3-manylinux_2_28_x86_64.whl (98.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m98.8/98.8 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
            "Downloading torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl (821.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m122.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Downloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchcodec-0.5-cp311-cp311-manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl (7.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m139.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wandb-0.21.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
            "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
            "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
            "Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
            "Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
            "Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m123.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mergedeep-1.3.4-py3-none-any.whl (6.4 kB)\n",
            "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m141.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orderly_set-5.5.0-py3-none-any.whl (13 kB)\n",
            "Downloading pillow-12.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m137.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
            "Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.12.3-py3-none-any.whl (462 kB)\n",
            "Downloading pydantic_core-2.41.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_xlib-0.33-py2.py3-none-any.whl (182 kB)\n",
            "Downloading pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (806 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m806.6/806.6 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyyaml_include-1.4.1-py3-none-any.whl (19 kB)\n",
            "Downloading regex-2025.9.18-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (798 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m799.0/799.0 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
            "Downloading sentry_sdk-2.42.0-py2.py3-none-any.whl (379 kB)\n",
            "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
            "Downloading imageio_ffmpeg-0.6.0-py3-none-manylinux2014_x86_64.whl (29.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m29.5/29.5 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m152.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-7.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (291 kB)\n",
            "Downloading xxhash-3.6.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
            "Downloading aiohttp-3.13.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
            "Downloading markupsafe-3.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading pfzy-0.3.4-py3-none-any.whl (8.5 kB)\n",
            "Downloading prompt_toolkit-3.0.52-py3-none-any.whl (391 kB)\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
            "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
            "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Downloading frozenlist-1.8.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (231 kB)\n",
            "Downloading multidict-6.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (246 kB)\n",
            "Downloading propcache-0.4.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (210 kB)\n",
            "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
            "Downloading yarl-1.22.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (365 kB)\n",
            "Downloading wcwidth-0.2.14-py2.py3-none-any.whl (37 kB)\n",
            "Building wheels for collected packages: lerobot, evdev\n",
            "  Building editable for lerobot (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lerobot: filename=lerobot-0.3.4-0.editable-py3-none-any.whl size=15449 sha256=821156f1b7a257618e10d3408b4052a16937cfc9440ab476b8a0fc411785ead8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_7vzjyqc/wheels/15/0d/02/b9c6ff1c78574dee99101ad231194b3425eb4cd784ce8c8338\n",
            "  Building wheel for evdev (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for evdev: filename=evdev-1.9.2-cp311-cp311-linux_x86_64.whl size=74951 sha256=f5ee2a42fa447b7e75b5516ecc63180546020ab6c5ac069dae5d7e1796872ba1\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/97/d0/ea1b02915719d1cdb6a8810aa7683524c7aceedc5812cdeed7\n",
            "Successfully built lerobot evdev\n",
            "Installing collected packages: pytz, pyserial, nvidia-cusparselt-cu12, mpmath, farama-notifications, zipp, xxhash, wcwidth, tzdata, typing-extensions, torchcodec, toml, termcolor, sympy, smmap, six, setuptools, sentry-sdk, safetensors, regex, pyyaml, pyarrow, psutil, protobuf, propcache, Pillow, pfzy, orderly-set, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, mypy-extensions, multidict, mergedeep, MarkupSafe, imageio-ffmpeg, hf-xet, hf-transfer, fsspec, frozenlist, filelock, evdev, einops, dill, cmake, cloudpickle, click, av, attrs, annotated-types, aiohappyeyeballs, yarl, typing-inspection, typing-inspect, triton, rerun-sdk, pyyaml-include, python-xlib, python-dateutil, pydantic-core, prompt-toolkit, opencv-python-headless, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, multiprocess, jsonlines, jinja2, importlib_metadata, imageio, huggingface-hub, gymnasium, gitdb, deepdiff, aiosignal, pynput, pydantic, pandas, nvidia-cusolver-cu12, InquirerPy, gitpython, draccus, diffusers, aiohttp, wandb, torch, torchvision, datasets, accelerate, lerobot\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 65.6.3\n",
            "    Uninstalling setuptools-65.6.3:\n",
            "      Successfully uninstalled setuptools-65.6.3\n",
            "Successfully installed InquirerPy-0.3.4 MarkupSafe-3.0.3 Pillow-12.0.0 accelerate-1.10.1 aiohappyeyeballs-2.6.1 aiohttp-3.13.1 aiosignal-1.4.0 annotated-types-0.7.0 attrs-25.4.0 av-15.1.0 click-8.3.0 cloudpickle-3.1.1 cmake-4.1.0 datasets-4.1.1 deepdiff-8.6.1 diffusers-0.35.2 dill-0.4.0 draccus-0.10.0 einops-0.8.1 evdev-1.9.2 farama-notifications-0.0.4 filelock-3.20.0 frozenlist-1.8.0 fsspec-2025.9.0 gitdb-4.0.12 gitpython-3.1.45 gymnasium-1.2.1 hf-transfer-0.1.9 hf-xet-1.1.10 huggingface-hub-0.35.3 imageio-2.37.0 imageio-ffmpeg-0.6.0 importlib_metadata-8.7.0 jinja2-3.1.6 jsonlines-4.0.0 lerobot-0.3.4 mergedeep-1.3.4 mpmath-1.3.0 multidict-6.7.0 multiprocess-0.70.16 mypy-extensions-1.1.0 networkx-3.5 numpy-2.2.6 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 opencv-python-headless-4.12.0.88 orderly-set-5.5.0 pandas-2.3.3 pfzy-0.3.4 prompt-toolkit-3.0.52 propcache-0.4.1 protobuf-6.33.0 psutil-7.1.0 pyarrow-21.0.0 pydantic-2.12.3 pydantic-core-2.41.4 pynput-1.8.1 pyserial-3.5 python-dateutil-2.9.0.post0 python-xlib-0.33 pytz-2025.2 pyyaml-6.0.3 pyyaml-include-1.4.1 regex-2025.9.18 rerun-sdk-0.26.0 safetensors-0.6.2 sentry-sdk-2.42.0 setuptools-80.9.0 six-1.17.0 smmap-5.0.2 sympy-1.14.0 termcolor-3.1.0 toml-0.10.2 torch-2.7.1 torchcodec-0.5 torchvision-0.22.1 triton-3.3.1 typing-extensions-4.15.0 typing-inspect-0.9.0 typing-inspection-0.4.2 tzdata-2025.2 wandb-0.21.4 wcwidth-0.2.14 xxhash-3.6.0 yarl-1.22.0 zipp-3.23.0\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/huggingface/lerobot.git\n",
        "!conda install ffmpeg=7.1.1 -c conda-forge\n",
        "!cd lerobot && pip install -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8Sn2wG4wldo"
      },
      "source": [
        "## Weights & Biases login\n",
        "This cell logs you into Weights & Biases (wandb) to enable experiment tracking and logging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PolVM_movEvp"
      },
      "outputs": [],
      "source": [
        "#!wandb login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUe3iIR9U2s7"
      },
      "source": [
        "## Conversion du dataset pour entrainement\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0AyI51DShDC",
        "outputId": "f10bc860-d52c-40a1-9fb5-b32cf351e276"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/site-packages (0.35.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from huggingface_hub) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface_hub) (2025.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/site-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from huggingface_hub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/site-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface_hub) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/site-packages (from huggingface_hub) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub) (2025.10.5)\n"
          ]
        }
      ],
      "source": [
        "# transformation du dataset\n",
        "!pip install --upgrade huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "1b06f88ce19b41fb96f5b019b03af7fb",
            "708417bc6e3f4a21b12fd8486855eac5",
            "790e449c8e094618951732971e6f5656",
            "7acdf04f26024200acbe10230ff7b767",
            "57859a913e504d3eba4264d66241667c",
            "1ae3f6348d59401ead0cf95da0a2180c",
            "eccc1ecd96104b3fbe5997387eeeb604",
            "f21d38ab465c453ca72db1ccb11adf2c",
            "bd35e0f2791c48b49c284be6530a5de3",
            "10c89a41e6534e8e89c0a7ca09915c5d",
            "efd5e00b93b546cd8031977947f36344",
            "f8638c06a73644be9edf13ace66c7d33",
            "e3248b80e6d24eeb9a7ef4e26253a35d",
            "e5f3be57bd1b478080449631ab9459bd",
            "af792aab9cc9446d81bca00344784d3a",
            "66bfb26ad52b466b9fc02e3665af2854",
            "44bcd9b678c843de85067e889b29269f",
            "f44eb5a19e0444e18b4fc3bdc8714260",
            "296f5243b2c14617a4a773dfe9cff433",
            "8f57fe58255049e4a5cb1a7e372e6970"
          ]
        },
        "id": "hf-5FnH0Ujub",
        "outputId": "4418cd65-da13-422a-9404-2c226aec5b5c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b06f88ce19b41fb96f5b019b03af7fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcEAw57XUieL",
        "outputId": "18f25994-3821-4d56-ebc0-f7bf86932e21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trying to download v3.0 version of the dataset from the hub...\n",
            "Dataset does not have an uploaded v3.0 version. Continuing with conversion.\n",
            "Fetching 10 files:   0% 0/10 [00:00<?, ?it/s]\n",
            "data/chunk-000/episode_000000.parquet:   0% 0.00/14.9k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "videos/chunk-000/observation.images.fron(‚Ä¶):   0% 0.00/3.00M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            ".gitattributes: 2.46kB [00:00, 734kB/s]\n",
            "Fetching 10 files:  10% 1/10 [00:00<00:03,  2.67it/s]\n",
            "\n",
            "\n",
            "tasks.jsonl: 100% 49.0/49.0 [00:00<00:00, 400kB/s]\n",
            "\n",
            "\n",
            "\n",
            "info.json: 3.85kB [00:00, 18.9MB/s]\n",
            "\n",
            "\n",
            "\n",
            "README.md: 4.34kB [00:00, 17.8MB/s]\n",
            "\n",
            "\n",
            "\n",
            "episodes.jsonl: 100% 70.0/70.0 [00:00<00:00, 661kB/s]\n",
            "\n",
            "\n",
            "\n",
            "episodes_stats.jsonl: 2.42kB [00:00, 15.2MB/s]\n",
            "\n",
            "\n",
            "\n",
            "videos/chunk-000/observation.images.top/(‚Ä¶):   0% 0.00/2.70M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "videos/chunk-000/observation.images.outs(‚Ä¶):   0% 0.00/2.96M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "videos/chunk-000/observation.images.fron(‚Ä¶): 100% 3.00M/3.00M [00:00<00:00, 4.00MB/s]\n",
            "\n",
            "\n",
            "\n",
            "videos/chunk-000/observation.images.top/(‚Ä¶): 100% 2.70M/2.70M [00:00<00:00, 6.20MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "videos/chunk-000/observation.images.outs(‚Ä¶): 100% 2.96M/2.96M [00:00<00:00, 6.14MB/s]\n",
            "\n",
            "data/chunk-000/episode_000000.parquet: 100% 14.9k/14.9k [00:00<00:00, 16.4kB/s]\n",
            "Fetching 10 files: 100% 10/10 [00:01<00:00,  8.24it/s]\n",
            "INFO 2025-10-18 14:14:51 1_to_v30.py:438 Converting info from /root/.cache/huggingface/lerobot/Heuzef/dataset_exemple_001 to /root/.cache/huggingface/lerobot/Heuzef/dataset_exemple_001_v30\n",
            "INFO 2025-10-18 14:14:51 1_to_v30.py:169 Converting tasks from /root/.cache/huggingface/lerobot/Heuzef/dataset_exemple_001 to /root/.cache/huggingface/lerobot/Heuzef/dataset_exemple_001_v30\n",
            "INFO 2025-10-18 14:14:51 1_to_v30.py:212 Converting data files from 1 episodes\n",
            "convert data files: 100% 1/1 [00:00<00:00, 1091.70it/s]\n",
            "INFO 2025-10-18 14:14:51 1_to_v30.py:264 Converting videos from /root/.cache/huggingface/lerobot/Heuzef/dataset_exemple_001 to /root/.cache/huggingface/lerobot/Heuzef/dataset_exemple_001_v30\n",
            "convert videos of observation.images.front: 100% 1/1 [00:00<00:00, 25.98it/s]\n",
            "convert videos of observation.images.outside: 100% 1/1 [00:00<00:00, 820.48it/s]\n",
            "convert videos of observation.images.top: 100% 1/1 [00:00<00:00, 543.30it/s]\n",
            "convert videos: 100% 1/1 [00:00<00:00, 17403.75it/s]\n",
            "INFO 2025-10-18 14:14:51 1_to_v30.py:405 Converting episodes metadata from /root/.cache/huggingface/lerobot/Heuzef/dataset_exemple_001 to /root/.cache/huggingface/lerobot/Heuzef/dataset_exemple_001_v30\n",
            "Generating train split: 1 examples [00:00, 16.42 examples/s]\n",
            "Creating parquet from Arrow format: 100% 1/1 [00:00<00:00, 185.66ba/s]\n",
            "tag=v3.0 probably doesn't exist. Skipping exception (404 Client Error. (Request ID: Root=1-68f3a0dc-4f927f3d218bcd2c46fffff6;92cbd1e3-dc69-4ee8-9c33-d05a84a73b4b)\n",
            "\n",
            "Revision Not Found for url: https://huggingface.co/api/datasets/Heuzef/dataset_exemple_001/tag/v3.0.\n",
            "Invalid rev id: v3.0)\n",
            "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            \n",
            "New Data Upload               : |          |  0.00B /  0.00B            \u001b[A\n",
            "\n",
            "  ...de/chunk-000/file-000.mp4:  77% 2.28M/2.96M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...hunk-000/file-000.parquet:   8% 1.30k/16.1k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...hunk-000/file-000.parquet:   8% 4.24k/52.3k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...le_001/meta/tasks.parquet:   8% 173/2.14k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...nt/chunk-000/file-000.mp4:   8% 243k/3.00M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...op/chunk-000/file-000.mp4:   8% 219k/2.70M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "  ...de/chunk-000/file-000.mp4:  77% 2.28M/2.96M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...hunk-000/file-000.parquet:   8% 1.30k/16.1k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...hunk-000/file-000.parquet:   8% 4.24k/52.3k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...le_001/meta/tasks.parquet:   8% 173/2.14k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...nt/chunk-000/file-000.mp4:   8% 243k/3.00M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (0 / 6)      :  31% 2.74M/8.74M [00:00<00:00, 6.79MB/s, 13.7MB/s  ]\n",
            "New Data Upload               :   8% 528k/6.52M [00:00<00:04, 1.31MB/s, 2.63MB/s  ]\u001b[A\n",
            "\n",
            "  ...de/chunk-000/file-000.mp4:  79% 2.34M/2.96M [00:00<00:02, 303kB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...hunk-000/file-000.parquet:  16% 2.60k/16.1k [00:00<00:02, 6.55kB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...hunk-000/file-000.parquet:  16% 8.47k/52.3k [00:00<00:02, 21.3kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...le_001/meta/tasks.parquet:  16% 346/2.14k [00:00<00:02, 872B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...nt/chunk-000/file-000.mp4:  16% 486k/3.00M [00:00<00:02, 1.23MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (0 / 6)      :  37% 3.27M/8.74M [00:00<00:01, 5.09MB/s, 8.19MB/s  ]\n",
            "New Data Upload               :  16% 1.06M/6.52M [00:00<00:02, 1.87MB/s, 2.64MB/s  ]\u001b[A\n",
            "\n",
            "  ...de/chunk-000/file-000.mp4:  91% 2.70M/2.96M [00:00<00:00, 1.06MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...hunk-000/file-000.parquet:  65% 10.4k/16.1k [00:00<00:00, 22.8kB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...hunk-000/file-000.parquet:  65% 33.9k/52.3k [00:00<00:00, 74.3kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...le_001/meta/tasks.parquet:  65% 1.39k/2.14k [00:00<00:00, 3.04kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...nt/chunk-000/file-000.mp4:  65% 1.95M/3.00M [00:00<00:00, 4.26MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (0 / 6)      :  74% 6.44M/8.74M [00:00<00:00, 9.09MB/s, 10.7MB/s  ]\n",
            "New Data Upload               :  65% 4.22M/6.52M [00:00<00:00, 7.07MB/s, 7.04MB/s  ]\u001b[A\n",
            "\n",
            "  ...de/chunk-000/file-000.mp4:  99% 2.94M/2.96M [00:00<00:00, 1.11MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...hunk-000/file-000.parquet:  97% 15.6k/16.1k [00:00<00:00, 23.9kB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...hunk-000/file-000.parquet:  97% 50.8k/52.3k [00:00<00:00, 77.8kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...le_001/meta/tasks.parquet:  97% 2.08k/2.14k [00:00<00:00, 3.18kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...nt/chunk-000/file-000.mp4:  97% 2.92M/3.00M [00:00<00:00, 4.47MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (0 / 6)      :  98% 8.55M/8.74M [00:01<00:00, 9.60MB/s, 10.7MB/s  ]\n",
            "New Data Upload               :  97% 6.34M/6.52M [00:01<00:00, 8.28MB/s, 7.92MB/s  ]\u001b[A\n",
            "\n",
            "  ...de/chunk-000/file-000.mp4:  99% 2.94M/2.96M [00:00<00:00, 828kB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...hunk-000/file-000.parquet:  97% 15.6k/16.1k [00:00<00:00, 17.9kB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...hunk-000/file-000.parquet:  97% 50.8k/52.3k [00:00<00:00, 58.3kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...le_001/meta/tasks.parquet:  97% 2.08k/2.14k [00:00<00:00, 2.39kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...nt/chunk-000/file-000.mp4:  97% 2.92M/3.00M [00:00<00:00, 3.35MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...op/chunk-000/file-000.mp4:  97% 2.63M/2.70M [00:00<00:00, 3.01MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "  ...de/chunk-000/file-000.mp4: 100% 2.96M/2.96M [00:00<00:00, 684kB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...hunk-000/file-000.parquet: 100% 16.1k/16.1k [00:00<00:00, 14.8kB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...hunk-000/file-000.parquet: 100% 52.3k/52.3k [00:00<00:00, 48.1kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...le_001/meta/tasks.parquet: 100% 2.14k/2.14k [00:00<00:00, 1.97kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...nt/chunk-000/file-000.mp4: 100% 3.00M/3.00M [00:00<00:00, 2.76MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (6 / 6)      : 100% 8.74M/8.74M [00:01<00:00, 5.05MB/s, 7.28MB/s  ]\n",
            "New Data Upload               : 100% 6.52M/6.52M [00:01<00:00, 4.39MB/s, 5.43MB/s  ]\u001b[A\n",
            "\n",
            "  ...de/chunk-000/file-000.mp4: 100% 2.96M/2.96M [00:01<00:00, 602kB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...hunk-000/file-000.parquet: 100% 16.1k/16.1k [00:01<00:00, 13.0kB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...hunk-000/file-000.parquet: 100% 52.3k/52.3k [00:01<00:00, 42.4kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...le_001/meta/tasks.parquet: 100% 2.14k/2.14k [00:01<00:00, 1.73kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...nt/chunk-000/file-000.mp4: 100% 3.00M/3.00M [00:01<00:00, 2.43MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...op/chunk-000/file-000.mp4: 100% 2.70M/2.70M [00:01<00:00, 2.19MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "  ...de/chunk-000/file-000.mp4: 100% 2.96M/2.96M [00:01<00:00, 570kB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...hunk-000/file-000.parquet: 100% 16.1k/16.1k [00:01<00:00, 12.3kB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...hunk-000/file-000.parquet: 100% 52.3k/52.3k [00:01<00:00, 40.1kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...le_001/meta/tasks.parquet: 100% 2.14k/2.14k [00:01<00:00, 1.64kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...nt/chunk-000/file-000.mp4: 100% 3.00M/3.00M [00:01<00:00, 2.30MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (6 / 6)      : 100% 8.74M/8.74M [00:01<00:00, 5.45MB/s, 6.24MB/s  ]\n",
            "New Data Upload               : 100% 6.52M/6.52M [00:01<00:00, 4.07MB/s, 4.66MB/s  ]\n",
            "  ...de/chunk-000/file-000.mp4: 100% 2.96M/2.96M [00:01<00:00, 569kB/s]\n",
            "  ...hunk-000/file-000.parquet: 100% 16.1k/16.1k [00:01<00:00, 12.3kB/s]\n",
            "  ...hunk-000/file-000.parquet: 100% 52.3k/52.3k [00:01<00:00, 40.1kB/s]\n",
            "  ...le_001/meta/tasks.parquet: 100% 2.14k/2.14k [00:01<00:00, 1.64kB/s]\n",
            "  ...nt/chunk-000/file-000.mp4: 100% 3.00M/3.00M [00:01<00:00, 2.30MB/s]\n",
            "  ...op/chunk-000/file-000.mp4: 100% 2.70M/2.70M [00:01<00:00, 2.07MB/s]\n"
          ]
        }
      ],
      "source": [
        "!python -m lerobot.datasets.v30.convert_dataset_v21_to_v30 --repo-id=Heuzef/dataset_exemple_001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CjTHkUIWSIY"
      },
      "source": [
        "## Gestion dossier outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wQoTTMw2A5Dk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# listing du dossier outputs\n",
        "!mkdir -p /content/outputs/train\n",
        "os.chdir(\"/content/outputs/train/\")\n",
        "!ls\n",
        "\n",
        "# suppression dossier entrainement si besoin de relancer. Sinon on a une exception\n",
        "#!rm -r /content/outputs/train/NOM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkzTo4mNwxaC"
      },
      "source": [
        "## Start training ACT with LeRobot\n",
        "\n",
        "This cell runs the `train.py` script from the `lerobot` library to train a robot control policy.  \n",
        "\n",
        "Make sure to adjust the following arguments to your setup:\n",
        "\n",
        "1. `--dataset.repo_id=YOUR_HF_USERNAME/YOUR_DATASET`:  \n",
        "   Replace this with the Hugging Face Hub repo ID where your dataset is stored, e.g., `pepijn223/il_gym0`.\n",
        "\n",
        "2. `--policy.type=act`:  \n",
        "   Specifies the policy configuration to use. `act` refers to [configuration_act.py](../lerobot/common/policies/act/configuration_act.py), which will automatically adapt to your dataset‚Äôs setup (e.g., number of motors and cameras).\n",
        "\n",
        "3. `--output_dir=outputs/train/...`:  \n",
        "   Directory where training logs and model checkpoints will be saved.\n",
        "\n",
        "4. `--job_name=...`:  \n",
        "   A name for this training job, used for logging and Weights & Biases.\n",
        "\n",
        "5. `--policy.device=cuda`:  \n",
        "   Use `cuda` if training on an NVIDIA GPU. Use `mps` for Apple Silicon, or `cpu` if no GPU is available.\n",
        "\n",
        "6. `--wandb.enable=true`:  \n",
        "   Enables Weights & Biases for visualizing training progress. You must be logged in via `wandb login` before running this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXAj52AKdvcO",
        "outputId": "08ad3355-5951-4067-9f0f-27a1e97f2e23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: lerobot_train.py [-h] [--config_path str] [--dataset str]\n",
            "                        [--dataset.repo_id str] [--dataset.root [str]]\n",
            "                        [--dataset.episodes [List]] [--image_transforms str]\n",
            "                        [--dataset.image_transforms.enable bool]\n",
            "                        [--dataset.image_transforms.max_num_transforms int]\n",
            "                        [--dataset.image_transforms.random_order bool]\n",
            "                        [--dataset.image_transforms.tfs Dict]\n",
            "                        [--dataset.revision [str]]\n",
            "                        [--dataset.use_imagenet_stats bool]\n",
            "                        [--dataset.video_backend str]\n",
            "                        [--dataset.streaming bool] [--env str]\n",
            "                        [--env.type {aloha,pusht,gym_manipulator,libero,metaworld}]\n",
            "                        [--env.visualization_width int]\n",
            "                        [--env.visualization_height int] [--robot str]\n",
            "                        [--env.robot.type {}] [--teleop str]\n",
            "                        [--env.teleop.type {}] [--processor str]\n",
            "                        [--env.processor.control_mode str] [--observation str]\n",
            "                        [--env.processor.observation.add_joint_velocity_to_observation bool]\n",
            "                        [--env.processor.observation.add_current_to_observation bool]\n",
            "                        [--env.processor.observation.display_cameras bool]\n",
            "                        [--image_preprocessing str]\n",
            "                        [--env.processor.image_preprocessing.crop_params_dict [Dict]]\n",
            "                        [--env.processor.image_preprocessing.resize_size [int int]]\n",
            "                        [--gripper str]\n",
            "                        [--env.processor.gripper.use_gripper bool]\n",
            "                        [--env.processor.gripper.gripper_penalty float]\n",
            "                        [--reset str]\n",
            "                        [--env.processor.reset.fixed_reset_joint_positions [Any]]\n",
            "                        [--env.processor.reset.reset_time_s float]\n",
            "                        [--env.processor.reset.control_time_s float]\n",
            "                        [--env.processor.reset.terminate_on_success bool]\n",
            "                        [--inverse_kinematics str]\n",
            "                        [--env.processor.inverse_kinematics.urdf_path [str]]\n",
            "                        [--env.processor.inverse_kinematics.target_frame_name [str]]\n",
            "                        [--env.processor.inverse_kinematics.end_effector_bounds [Dict]]\n",
            "                        [--env.processor.inverse_kinematics.end_effector_step_sizes [Dict]]\n",
            "                        [--reward_classifier str]\n",
            "                        [--env.processor.reward_classifier.pretrained_path [str]]\n",
            "                        [--env.processor.reward_classifier.success_threshold float]\n",
            "                        [--env.processor.reward_classifier.success_reward float]\n",
            "                        [--env.processor.max_gripper_pos [float]]\n",
            "                        [--env.name str] [--env.camera_name str]\n",
            "                        [--env.init_states bool]\n",
            "                        [--env.camera_name_mapping [Dict]]\n",
            "                        [--env.observation_height int]\n",
            "                        [--env.observation_width int] [--env.task str]\n",
            "                        [--env.fps int] [--env.features Dict]\n",
            "                        [--env.features_map Dict]\n",
            "                        [--env.max_parallel_tasks int]\n",
            "                        [--env.disable_env_checker bool]\n",
            "                        [--env.episode_length int] [--env.obs_type str]\n",
            "                        [--env.render_mode str] [--env.multitask_eval bool]\n",
            "                        [--policy str]\n",
            "                        [--policy.type {act,diffusion,pi0,pi05,smolvla,tdmpc,vqbet,sac,reward_classifier}]\n",
            "                        [--policy.replace_final_stride_with_dilation int]\n",
            "                        [--policy.pre_norm bool] [--policy.dim_model int]\n",
            "                        [--policy.n_heads int] [--policy.dim_feedforward int]\n",
            "                        [--policy.feedforward_activation str]\n",
            "                        [--policy.n_encoder_layers int]\n",
            "                        [--policy.n_decoder_layers int]\n",
            "                        [--policy.use_vae bool]\n",
            "                        [--policy.n_vae_encoder_layers int]\n",
            "                        [--policy.temporal_ensemble_coeff [float]]\n",
            "                        [--policy.kl_weight float]\n",
            "                        [--policy.optimizer_lr_backbone float]\n",
            "                        [--policy.drop_n_last_frames int]\n",
            "                        [--policy.use_separate_rgb_encoder_per_camera bool]\n",
            "                        [--policy.down_dims int [int, ...]]\n",
            "                        [--policy.kernel_size int] [--policy.n_groups int]\n",
            "                        [--policy.diffusion_step_embed_dim int]\n",
            "                        [--policy.use_film_scale_modulation bool]\n",
            "                        [--policy.noise_scheduler_type str]\n",
            "                        [--policy.num_train_timesteps int]\n",
            "                        [--policy.beta_schedule str]\n",
            "                        [--policy.beta_start float] [--policy.beta_end float]\n",
            "                        [--policy.prediction_type str]\n",
            "                        [--policy.clip_sample bool]\n",
            "                        [--policy.clip_sample_range float]\n",
            "                        [--policy.do_mask_loss_for_padding bool]\n",
            "                        [--policy.scheduler_name str]\n",
            "                        [--policy.paligemma_variant str]\n",
            "                        [--policy.action_expert_variant str]\n",
            "                        [--policy.dtype str]\n",
            "                        [--policy.num_inference_steps int]\n",
            "                        [--policy.time_sampling_beta_alpha float]\n",
            "                        [--policy.time_sampling_beta_beta float]\n",
            "                        [--policy.time_sampling_scale float]\n",
            "                        [--policy.time_sampling_offset float]\n",
            "                        [--policy.image_resolution int int]\n",
            "                        [--policy.gradient_checkpointing bool]\n",
            "                        [--policy.compile_model bool]\n",
            "                        [--policy.compile_mode str] [--policy.chunk_size int]\n",
            "                        [--policy.max_state_dim int]\n",
            "                        [--policy.max_action_dim int]\n",
            "                        [--policy.resize_imgs_with_padding int int]\n",
            "                        [--policy.empty_cameras int]\n",
            "                        [--policy.adapt_to_pi_aloha bool]\n",
            "                        [--policy.use_delta_joint_actions_aloha bool]\n",
            "                        [--policy.tokenizer_max_length int]\n",
            "                        [--policy.num_steps int] [--policy.use_cache bool]\n",
            "                        [--policy.train_expert_only bool]\n",
            "                        [--policy.train_state_proj bool]\n",
            "                        [--policy.optimizer_grad_clip_norm float]\n",
            "                        [--policy.scheduler_decay_steps int]\n",
            "                        [--policy.scheduler_decay_lr float]\n",
            "                        [--policy.vlm_model_name str]\n",
            "                        [--policy.load_vlm_weights bool]\n",
            "                        [--policy.add_image_special_tokens bool]\n",
            "                        [--policy.attention_mode str]\n",
            "                        [--policy.prefix_length int]\n",
            "                        [--policy.pad_language_to str]\n",
            "                        [--policy.num_expert_layers int]\n",
            "                        [--policy.num_vlm_layers int]\n",
            "                        [--policy.self_attn_every_n_layers int]\n",
            "                        [--policy.expert_width_multiplier float]\n",
            "                        [--policy.min_period float]\n",
            "                        [--policy.max_period float]\n",
            "                        [--policy.n_action_repeats int] [--policy.horizon int]\n",
            "                        [--policy.n_action_steps int]\n",
            "                        [--policy.q_ensemble_size int] [--policy.mlp_dim int]\n",
            "                        [--policy.use_mpc bool] [--policy.cem_iterations int]\n",
            "                        [--policy.max_std float] [--policy.min_std float]\n",
            "                        [--policy.n_gaussian_samples int]\n",
            "                        [--policy.n_pi_samples int]\n",
            "                        [--policy.uncertainty_regularizer_coeff float]\n",
            "                        [--policy.n_elites int]\n",
            "                        [--policy.elite_weighting_temperature float]\n",
            "                        [--policy.gaussian_mean_momentum float]\n",
            "                        [--policy.max_random_shift_ratio float]\n",
            "                        [--policy.reward_coeff float]\n",
            "                        [--policy.expectile_weight float]\n",
            "                        [--policy.value_coeff float]\n",
            "                        [--policy.consistency_coeff float]\n",
            "                        [--policy.advantage_scaling float]\n",
            "                        [--policy.pi_coeff float]\n",
            "                        [--policy.temporal_decay_coeff float]\n",
            "                        [--policy.target_model_momentum float]\n",
            "                        [--policy.n_action_pred_token int]\n",
            "                        [--policy.action_chunk_size int]\n",
            "                        [--policy.vision_backbone str]\n",
            "                        [--policy.crop_shape [int int]]\n",
            "                        [--policy.crop_is_random bool]\n",
            "                        [--policy.pretrained_backbone_weights [str]]\n",
            "                        [--policy.use_group_norm bool]\n",
            "                        [--policy.spatial_softmax_num_keypoints int]\n",
            "                        [--policy.n_vqvae_training_steps int]\n",
            "                        [--policy.vqvae_n_embed int]\n",
            "                        [--policy.vqvae_embedding_dim int]\n",
            "                        [--policy.vqvae_enc_hidden_dim int]\n",
            "                        [--policy.gpt_block_size int]\n",
            "                        [--policy.gpt_input_dim int]\n",
            "                        [--policy.gpt_output_dim int]\n",
            "                        [--policy.gpt_n_layer int] [--policy.gpt_n_head int]\n",
            "                        [--policy.gpt_hidden_dim int] [--policy.dropout float]\n",
            "                        [--policy.offset_loss_weight float]\n",
            "                        [--policy.primary_code_loss_weight float]\n",
            "                        [--policy.secondary_code_loss_weight float]\n",
            "                        [--policy.bet_softmax_temperature float]\n",
            "                        [--policy.sequentially_select bool]\n",
            "                        [--policy.optimizer_lr float]\n",
            "                        [--policy.optimizer_betas Any]\n",
            "                        [--policy.optimizer_eps float]\n",
            "                        [--policy.optimizer_weight_decay float]\n",
            "                        [--policy.optimizer_vqvae_lr float]\n",
            "                        [--policy.optimizer_vqvae_weight_decay float]\n",
            "                        [--policy.scheduler_warmup_steps int]\n",
            "                        [--policy.dataset_stats [Dict]]\n",
            "                        [--policy.storage_device str]\n",
            "                        [--policy.vision_encoder_name [str]]\n",
            "                        [--policy.freeze_vision_encoder bool]\n",
            "                        [--policy.image_encoder_hidden_dim int]\n",
            "                        [--policy.shared_encoder bool]\n",
            "                        [--policy.num_discrete_actions [int]]\n",
            "                        [--policy.online_steps int]\n",
            "                        [--policy.online_buffer_capacity int]\n",
            "                        [--policy.offline_buffer_capacity int]\n",
            "                        [--policy.async_prefetch bool]\n",
            "                        [--policy.online_step_before_learning int]\n",
            "                        [--policy.policy_update_freq int]\n",
            "                        [--policy.discount float]\n",
            "                        [--policy.temperature_init float]\n",
            "                        [--policy.num_critics int]\n",
            "                        [--policy.num_subsample_critics [int]]\n",
            "                        [--policy.critic_lr float] [--policy.actor_lr float]\n",
            "                        [--policy.temperature_lr float]\n",
            "                        [--policy.critic_target_update_weight float]\n",
            "                        [--policy.utd_ratio int]\n",
            "                        [--policy.state_encoder_hidden_dim int]\n",
            "                        [--policy.target_entropy [float]]\n",
            "                        [--policy.use_backup_entropy bool]\n",
            "                        [--critic_network_kwargs str]\n",
            "                        [--policy.critic_network_kwargs.hidden_dims List]\n",
            "                        [--policy.critic_network_kwargs.activate_final bool]\n",
            "                        [--policy.critic_network_kwargs.final_activation [str]]\n",
            "                        [--actor_network_kwargs str]\n",
            "                        [--policy.actor_network_kwargs.hidden_dims List]\n",
            "                        [--policy.actor_network_kwargs.activate_final bool]\n",
            "                        [--policy_kwargs str]\n",
            "                        [--policy.policy_kwargs.use_tanh_squash bool]\n",
            "                        [--policy.policy_kwargs.std_min float]\n",
            "                        [--policy.policy_kwargs.std_max float]\n",
            "                        [--policy.policy_kwargs.init_final float]\n",
            "                        [--discrete_critic_network_kwargs str]\n",
            "                        [--policy.discrete_critic_network_kwargs.hidden_dims List]\n",
            "                        [--policy.discrete_critic_network_kwargs.activate_final bool]\n",
            "                        [--policy.discrete_critic_network_kwargs.final_activation [str]]\n",
            "                        [--actor_learner_config str]\n",
            "                        [--policy.actor_learner_config.learner_host str]\n",
            "                        [--policy.actor_learner_config.learner_port int]\n",
            "                        [--policy.actor_learner_config.policy_parameters_push_frequency int]\n",
            "                        [--policy.actor_learner_config.queue_get_timeout float]\n",
            "                        [--concurrency str] [--policy.concurrency.actor str]\n",
            "                        [--policy.concurrency.learner str]\n",
            "                        [--policy.use_torch_compile bool]\n",
            "                        [--policy.n_obs_steps int]\n",
            "                        [--policy.input_features Dict]\n",
            "                        [--policy.output_features Dict] [--policy.device str]\n",
            "                        [--policy.use_amp bool] [--policy.push_to_hub bool]\n",
            "                        [--policy.repo_id [str]] [--policy.private [bool]]\n",
            "                        [--policy.tags [List]] [--policy.license [str]]\n",
            "                        [--policy.pretrained_path [str]] [--policy.name str]\n",
            "                        [--policy.num_classes int] [--policy.hidden_dim int]\n",
            "                        [--policy.latent_dim int]\n",
            "                        [--policy.image_embedding_pooling_dim int]\n",
            "                        [--policy.dropout_rate float]\n",
            "                        [--policy.model_name str] [--policy.model_type str]\n",
            "                        [--policy.num_cameras int]\n",
            "                        [--policy.learning_rate float]\n",
            "                        [--policy.weight_decay float]\n",
            "                        [--policy.grad_clip_norm float]\n",
            "                        [--policy.normalization_mapping Dict]\n",
            "                        [--output_dir [Path]] [--job_name [str]]\n",
            "                        [--resume bool] [--seed [int]] [--num_workers int]\n",
            "                        [--batch_size int] [--steps int] [--eval_freq int]\n",
            "                        [--log_freq int] [--save_checkpoint bool]\n",
            "                        [--save_freq int] [--use_policy_training_preset bool]\n",
            "                        [--optimizer str]\n",
            "                        [--optimizer.type {adam,adamw,sgd,multi_adam}]\n",
            "                        [--optimizer.betas float float]\n",
            "                        [--optimizer.eps float] [--optimizer.momentum float]\n",
            "                        [--optimizer.dampening float]\n",
            "                        [--optimizer.nesterov bool] [--optimizer.lr float]\n",
            "                        [--optimizer.weight_decay float]\n",
            "                        [--optimizer.grad_clip_norm float]\n",
            "                        [--optimizer.optimizer_groups Dict] [--scheduler str]\n",
            "                        [--scheduler.type {diffuser,vqbet,cosine_decay_with_warmup}]\n",
            "                        [--scheduler.name str]\n",
            "                        [--scheduler.num_vqvae_training_steps int]\n",
            "                        [--scheduler.num_cycles float]\n",
            "                        [--scheduler.num_warmup_steps int]\n",
            "                        [--scheduler.num_decay_steps int]\n",
            "                        [--scheduler.peak_lr float]\n",
            "                        [--scheduler.decay_lr float] [--eval str]\n",
            "                        [--eval.n_episodes int] [--eval.batch_size int]\n",
            "                        [--eval.use_async_envs bool] [--wandb str]\n",
            "                        [--wandb.enable bool] [--wandb.disable_artifact bool]\n",
            "                        [--wandb.project str] [--wandb.entity [str]]\n",
            "                        [--wandb.notes [str]] [--wandb.run_id [str]]\n",
            "                        [--wandb.mode [str]]\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --config_path str     Path for a config file to parse with draccus (default:\n",
            "                        None)\n",
            "  --dataset str         Config file for dataset (default: None)\n",
            "  --image_transforms str\n",
            "                        Config file for image_transforms (default: None)\n",
            "  --env str             Config file for env (default: None)\n",
            "  --robot str           Config file for robot (default: None)\n",
            "  --teleop str          Config file for teleop (default: None)\n",
            "  --processor str       Config file for processor (default: None)\n",
            "  --observation str     Config file for observation (default: None)\n",
            "  --image_preprocessing str\n",
            "                        Config file for image_preprocessing (default: None)\n",
            "  --gripper str         Config file for gripper (default: None)\n",
            "  --reset str           Config file for reset (default: None)\n",
            "  --inverse_kinematics str\n",
            "                        Config file for inverse_kinematics (default: None)\n",
            "  --reward_classifier str\n",
            "                        Config file for reward_classifier (default: None)\n",
            "  --policy str          Config file for policy (default: None)\n",
            "  --critic_network_kwargs str\n",
            "                        Config file for critic_network_kwargs (default: None)\n",
            "  --actor_network_kwargs str\n",
            "                        Config file for actor_network_kwargs (default: None)\n",
            "  --policy_kwargs str   Config file for policy_kwargs (default: None)\n",
            "  --discrete_critic_network_kwargs str\n",
            "                        Config file for discrete_critic_network_kwargs\n",
            "                        (default: None)\n",
            "  --actor_learner_config str\n",
            "                        Config file for actor_learner_config (default: None)\n",
            "  --concurrency str     Config file for concurrency (default: None)\n",
            "  --optimizer str       Config file for optimizer (default: None)\n",
            "  --scheduler str       Config file for scheduler (default: None)\n",
            "  --eval str            Config file for eval (default: None)\n",
            "  --wandb str           Config file for wandb (default: None)\n",
            "\n",
            "TrainPipelineConfig:\n",
            "\n",
            "  --output_dir [Path]   Set `dir` to where you would like to save all of the\n",
            "                        run outputs. If you run another training session with\n",
            "                        the same value for `dir` its contents will be\n",
            "                        overwritten unless you set `resume` to true. (default:\n",
            "                        None)\n",
            "  --job_name [str]\n",
            "  --resume bool         Set `resume` to true to resume a previous run. In\n",
            "                        order for this to work, you will need to make sure\n",
            "                        `dir` is the directory of an existing run with at\n",
            "                        least one checkpoint in it. Note that when resuming a\n",
            "                        run, the default behavior is to use the configuration\n",
            "                        from the checkpoint, regardless of what's provided\n",
            "                        with the training command at the time of resumption.\n",
            "                        (default: False)\n",
            "  --seed [int]          `seed` is used for training (eg: model initialization,\n",
            "                        dataset shuffling) AND for the evaluation\n",
            "                        environments. (default: 1000)\n",
            "  --num_workers int     Number of workers for the dataloader. (default: 4)\n",
            "  --batch_size int      \n",
            "  --steps int           \n",
            "  --eval_freq int       \n",
            "  --log_freq int        \n",
            "  --save_checkpoint bool\n",
            "  --save_freq int       Checkpoint is saved every `save_freq` training\n",
            "                        iterations and after the last training step. (default:\n",
            "                        20000)\n",
            "  --use_policy_training_preset bool\n",
            "\n",
            "DatasetConfig ['dataset']:\n",
            "\n",
            "  --dataset.repo_id str\n",
            "                        You may provide a list of datasets here. `train.py`\n",
            "                        creates them all and concatenates them. Note: only\n",
            "                        data keys common between the datasets are kept. Each\n",
            "                        dataset gets and additional transform that inserts the\n",
            "                        \"dataset_index\" into the returned item. The index\n",
            "                        mapping is made according to the order in which the\n",
            "                        datasets are provided. (default: None)\n",
            "  --dataset.root [str]  Root directory where the dataset will be stored (e.g.\n",
            "                        'dataset/path'). (default: None)\n",
            "  --dataset.episodes [List]\n",
            "  --dataset.revision [str]\n",
            "  --dataset.use_imagenet_stats bool\n",
            "  --dataset.video_backend str\n",
            "  --dataset.streaming bool\n",
            "\n",
            "ImageTransformsConfig ['dataset.image_transforms']:\n",
            "  \n",
            "      These transforms are all using standard torchvision.transforms.v2\n",
            "      You can find out how these transformations affect images here:\n",
            "      https://pytorch.org/vision/0.18/auto_examples/transforms/plot_transforms_illustrations.html\n",
            "      We use a custom RandomSubsetApply container to sample them.\n",
            "      \n",
            "\n",
            "  --dataset.image_transforms.enable bool\n",
            "                        Set this flag to `true` to enable transforms during\n",
            "                        training (default: False)\n",
            "  --dataset.image_transforms.max_num_transforms int\n",
            "                        This is the maximum number of transforms (sampled from\n",
            "                        these below) that will be applied to each frame. It's\n",
            "                        an integer in the interval [1,\n",
            "                        number_of_available_transforms]. (default: 3)\n",
            "  --dataset.image_transforms.random_order bool\n",
            "                        By default, transforms are applied in Torchvision's\n",
            "                        suggested order (shown below). Set this to True to\n",
            "                        apply them in a random order. (default: False)\n",
            "  --dataset.image_transforms.tfs Dict\n",
            "\n",
            "Optional ['env']:\n",
            "\n",
            "EnvConfig ['env']:\n",
            "\n",
            "  --env.type {aloha,pusht,gym_manipulator,libero,metaworld}\n",
            "                        Which type of EnvConfig ['env'] to use (default: None)\n",
            "\n",
            "AlohaEnv ['env']:\n",
            "\n",
            "  --env.task [str]      \n",
            "  --env.fps int         \n",
            "  --env.features Dict   \n",
            "  --env.features_map Dict\n",
            "  --env.max_parallel_tasks int\n",
            "  --env.disable_env_checker bool\n",
            "  --env.episode_length int\n",
            "  --env.obs_type str    \n",
            "  --env.observation_height int\n",
            "  --env.observation_width int\n",
            "  --env.render_mode str\n",
            "\n",
            "PushtEnv ['env']:\n",
            "\n",
            "  --env.task [str]      \n",
            "  --env.fps int         \n",
            "  --env.features Dict   \n",
            "  --env.features_map Dict\n",
            "  --env.max_parallel_tasks int\n",
            "  --env.disable_env_checker bool\n",
            "  --env.episode_length int\n",
            "  --env.obs_type str    \n",
            "  --env.render_mode str\n",
            "  --env.visualization_width int\n",
            "  --env.visualization_height int\n",
            "  --env.observation_height int\n",
            "  --env.observation_width int\n",
            "\n",
            "HILSerlRobotEnvConfig ['env']:\n",
            "  Configuration for the HILSerlRobotEnv environment.\n",
            "\n",
            "  --env.task [str]\n",
            "  --env.fps int         \n",
            "  --env.features Dict   \n",
            "  --env.features_map Dict\n",
            "  --env.max_parallel_tasks int\n",
            "  --env.disable_env_checker bool\n",
            "  --env.name str        \n",
            "\n",
            "Optional ['env.robot']:\n",
            "\n",
            "RobotConfig ['env.robot']:\n",
            "\n",
            "  --env.robot.type {}   Which type of RobotConfig ['env.robot'] to use\n",
            "                        (default: None)\n",
            "\n",
            "Optional ['env.teleop']:\n",
            "\n",
            "TeleoperatorConfig ['env.teleop']:\n",
            "\n",
            "  --env.teleop.type {}  Which type of TeleoperatorConfig ['env.teleop'] to use\n",
            "                        (default: None)\n",
            "\n",
            "HILSerlProcessorConfig ['env.processor']:\n",
            "  Configuration for environment processing pipeline.\n",
            "\n",
            "  --env.processor.control_mode str\n",
            "  --env.processor.max_gripper_pos [float]\n",
            "\n",
            "Optional ['env.processor.observation']:\n",
            "\n",
            "ObservationConfig ['env.processor.observation']:\n",
            "  Configuration for observation processing.\n",
            "\n",
            "  --env.processor.observation.add_joint_velocity_to_observation bool\n",
            "  --env.processor.observation.add_current_to_observation bool\n",
            "  --env.processor.observation.display_cameras bool\n",
            "\n",
            "Optional ['env.processor.image_preprocessing']:\n",
            "\n",
            "ImagePreprocessingConfig ['env.processor.image_preprocessing']:\n",
            "\n",
            "  --env.processor.image_preprocessing.crop_params_dict [Dict]\n",
            "  --env.processor.image_preprocessing.resize_size [int int]\n",
            "\n",
            "Optional ['env.processor.gripper']:\n",
            "\n",
            "GripperConfig ['env.processor.gripper']:\n",
            "  Configuration for gripper control and penalties.\n",
            "\n",
            "  --env.processor.gripper.use_gripper bool\n",
            "  --env.processor.gripper.gripper_penalty float\n",
            "\n",
            "Optional ['env.processor.reset']:\n",
            "\n",
            "ResetConfig ['env.processor.reset']:\n",
            "  Configuration for environment reset behavior.\n",
            "\n",
            "  --env.processor.reset.fixed_reset_joint_positions [Any]\n",
            "  --env.processor.reset.reset_time_s float\n",
            "  --env.processor.reset.control_time_s float\n",
            "  --env.processor.reset.terminate_on_success bool\n",
            "\n",
            "Optional ['env.processor.inverse_kinematics']:\n",
            "\n",
            "InverseKinematicsConfig ['env.processor.inverse_kinematics']:\n",
            "  Configuration for inverse kinematics processing.\n",
            "\n",
            "  --env.processor.inverse_kinematics.urdf_path [str]\n",
            "  --env.processor.inverse_kinematics.target_frame_name [str]\n",
            "  --env.processor.inverse_kinematics.end_effector_bounds [Dict]\n",
            "  --env.processor.inverse_kinematics.end_effector_step_sizes [Dict]\n",
            "\n",
            "Optional ['env.processor.reward_classifier']:\n",
            "\n",
            "RewardClassifierConfig ['env.processor.reward_classifier']:\n",
            "  Configuration for reward classification.\n",
            "\n",
            "  --env.processor.reward_classifier.pretrained_path [str]\n",
            "  --env.processor.reward_classifier.success_threshold float\n",
            "  --env.processor.reward_classifier.success_reward float\n",
            "\n",
            "LiberoEnv ['env']:\n",
            "\n",
            "  --env.task str        can also choose libero_spatial, libero_object, etc.\n",
            "                        (default: libero_10)\n",
            "  --env.fps int         \n",
            "  --env.features Dict   \n",
            "  --env.features_map Dict\n",
            "  --env.max_parallel_tasks int\n",
            "  --env.disable_env_checker bool\n",
            "  --env.episode_length int\n",
            "  --env.obs_type str    \n",
            "  --env.render_mode str\n",
            "  --env.camera_name str\n",
            "  --env.init_states bool\n",
            "  --env.camera_name_mapping [Dict]\n",
            "  --env.observation_height int\n",
            "  --env.observation_width int\n",
            "\n",
            "MetaworldEnv ['env']:\n",
            "\n",
            "  --env.task str        add all tasks (default: metaworld-push-v2)\n",
            "  --env.fps int         \n",
            "  --env.features Dict   \n",
            "  --env.features_map Dict\n",
            "  --env.max_parallel_tasks int\n",
            "  --env.disable_env_checker bool\n",
            "  --env.episode_length int\n",
            "  --env.obs_type str    \n",
            "  --env.render_mode str\n",
            "  --env.multitask_eval bool\n",
            "\n",
            "Optional ['policy']:\n",
            "\n",
            "PreTrainedConfig ['policy']:\n",
            "  \n",
            "      Base configuration class for policy models.\n",
            "  \n",
            "      Args:\n",
            "          n_obs_steps: Number of environment steps worth of observations to pass to the policy (takes the\n",
            "              current step and additional steps going back).\n",
            "          input_shapes: A dictionary defining the shapes of the input data for the policy.\n",
            "          output_shapes: A dictionary defining the shapes of the output data for the policy.\n",
            "          input_normalization_modes: A dictionary with key representing the modality and the value specifies the\n",
            "              normalization mode to apply.\n",
            "          output_normalization_modes: Similar dictionary as `input_normalization_modes`, but to unnormalize to\n",
            "              the original scale.\n",
            "      \n",
            "\n",
            "  --policy.type {act,diffusion,pi0,pi05,smolvla,tdmpc,vqbet,sac,reward_classifier}\n",
            "                        Which type of PreTrainedConfig ['policy'] to use\n",
            "                        (default: None)\n",
            "\n",
            "ACTConfig ['policy']:\n",
            "  Configuration class for the Action Chunking Transformers policy.\n",
            "  \n",
            "      Defaults are configured for training on bimanual Aloha tasks like \"insertion\" or \"transfer\".\n",
            "  \n",
            "      The parameters you will most likely need to change are the ones which depend on the environment / sensors.\n",
            "      Those are: `input_shapes` and 'output_shapes`.\n",
            "  \n",
            "      Notes on the inputs and outputs:\n",
            "          - Either:\n",
            "              - At least one key starting with \"observation.image is required as an input.\n",
            "                AND/OR\n",
            "              - The key \"observation.environment_state\" is required as input.\n",
            "          - If there are multiple keys beginning with \"observation.images.\" they are treated as multiple camera\n",
            "            views. Right now we only support all images having the same shape.\n",
            "          - May optionally work without an \"observation.state\" key for the proprioceptive robot state.\n",
            "          - \"action\" is required as an output key.\n",
            "  \n",
            "      Args:\n",
            "          n_obs_steps: Number of environment steps worth of observations to pass to the policy (takes the\n",
            "              current step and additional steps going back).\n",
            "          chunk_size: The size of the action prediction \"chunks\" in units of environment steps.\n",
            "          n_action_steps: The number of action steps to run in the environment for one invocation of the policy.\n",
            "              This should be no greater than the chunk size. For example, if the chunk size size 100, you may\n",
            "              set this to 50. This would mean that the model predicts 100 steps worth of actions, runs 50 in the\n",
            "              environment, and throws the other 50 out.\n",
            "          input_shapes: A dictionary defining the shapes of the input data for the policy. The key represents\n",
            "              the input data name, and the value is a list indicating the dimensions of the corresponding data.\n",
            "              For example, \"observation.image\" refers to an input from a camera with dimensions [3, 96, 96],\n",
            "              indicating it has three color channels and 96x96 resolution. Importantly, `input_shapes` doesn't\n",
            "              include batch dimension or temporal dimension.\n",
            "          output_shapes: A dictionary defining the shapes of the output data for the policy. The key represents\n",
            "              the output data name, and the value is a list indicating the dimensions of the corresponding data.\n",
            "              For example, \"action\" refers to an output shape of [14], indicating 14-dimensional actions.\n",
            "              Importantly, `output_shapes` doesn't include batch dimension or temporal dimension.\n",
            "          input_normalization_modes: A dictionary with key representing the modality (e.g. \"observation.state\"),\n",
            "              and the value specifies the normalization mode to apply. The two available modes are \"mean_std\"\n",
            "              which subtracts the mean and divides by the standard deviation and \"min_max\" which rescale in a\n",
            "              [-1, 1] range.\n",
            "          output_normalization_modes: Similar dictionary as `normalize_input_modes`, but to unnormalize to the\n",
            "              original scale. Note that this is also used for normalizing the training targets.\n",
            "          vision_backbone: Name of the torchvision resnet backbone to use for encoding images.\n",
            "          pretrained_backbone_weights: Pretrained weights from torchvision to initialize the backbone.\n",
            "              `None` means no pretrained weights.\n",
            "          replace_final_stride_with_dilation: Whether to replace the ResNet's final 2x2 stride with a dilated\n",
            "              convolution.\n",
            "          pre_norm: Whether to use \"pre-norm\" in the transformer blocks.\n",
            "          dim_model: The transformer blocks' main hidden dimension.\n",
            "          n_heads: The number of heads to use in the transformer blocks' multi-head attention.\n",
            "          dim_feedforward: The dimension to expand the transformer's hidden dimension to in the feed-forward\n",
            "              layers.\n",
            "          feedforward_activation: The activation to use in the transformer block's feed-forward layers.\n",
            "          n_encoder_layers: The number of transformer layers to use for the transformer encoder.\n",
            "          n_decoder_layers: The number of transformer layers to use for the transformer decoder.\n",
            "          use_vae: Whether to use a variational objective during training. This introduces another transformer\n",
            "              which is used as the VAE's encoder (not to be confused with the transformer encoder - see\n",
            "              documentation in the policy class).\n",
            "          latent_dim: The VAE's latent dimension.\n",
            "          n_vae_encoder_layers: The number of transformer layers to use for the VAE's encoder.\n",
            "          temporal_ensemble_coeff: Coefficient for the exponential weighting scheme to apply for temporal\n",
            "              ensembling. Defaults to None which means temporal ensembling is not used. `n_action_steps` must be\n",
            "              1 when using this feature, as inference needs to happen at every step to form an ensemble. For\n",
            "              more information on how ensembling works, please see `ACTTemporalEnsembler`.\n",
            "          dropout: Dropout to use in the transformer layers (see code for details).\n",
            "          kl_weight: The weight to use for the KL-divergence component of the loss if the variational objective\n",
            "              is enabled. Loss is then calculated as: `reconstruction_loss + kl_weight * kld_loss`.\n",
            "      \n",
            "\n",
            "  --policy.n_obs_steps int\n",
            "  --policy.input_features Dict\n",
            "  --policy.output_features Dict\n",
            "  --policy.device [str]\n",
            "                        cuda | cpu | mp (default: None)\n",
            "  --policy.use_amp bool\n",
            "                        `use_amp` determines whether to use Automatic Mixed\n",
            "                        Precision (AMP) for training and evaluation. With AMP,\n",
            "                        automatic gradient scaling is used. (default: False)\n",
            "  --policy.push_to_hub bool\n",
            "  --policy.repo_id [str]\n",
            "  --policy.private [bool]\n",
            "                        Upload on private repository on the Hugging Face hub.\n",
            "                        (default: None)\n",
            "  --policy.tags [List]  Add tags to your policy on the hub. (default: None)\n",
            "  --policy.license [str]\n",
            "                        Add tags to your policy on the hub. (default: None)\n",
            "  --policy.pretrained_path [str]\n",
            "                        Either the repo ID of a model hosted on the Hub or a\n",
            "                        path to a directory containing weights saved using\n",
            "                        `Policy.save_pretrained`. If not provided, the policy\n",
            "                        is initialized from scratch. (default: None)\n",
            "  --policy.chunk_size int\n",
            "  --policy.n_action_steps int\n",
            "  --policy.normalization_mapping Dict\n",
            "  --policy.vision_backbone str\n",
            "  --policy.pretrained_backbone_weights [str]\n",
            "  --policy.replace_final_stride_with_dilation int\n",
            "  --policy.pre_norm bool\n",
            "  --policy.dim_model int\n",
            "  --policy.n_heads int  \n",
            "  --policy.dim_feedforward int\n",
            "  --policy.feedforward_activation str\n",
            "  --policy.n_encoder_layers int\n",
            "  --policy.n_decoder_layers int\n",
            "  --policy.use_vae bool\n",
            "  --policy.latent_dim int\n",
            "  --policy.n_vae_encoder_layers int\n",
            "  --policy.temporal_ensemble_coeff [float]\n",
            "  --policy.dropout float\n",
            "  --policy.kl_weight float\n",
            "  --policy.optimizer_lr float\n",
            "                        Training preset (default: 1e-05)\n",
            "  --policy.optimizer_weight_decay float\n",
            "  --policy.optimizer_lr_backbone float\n",
            "\n",
            "DiffusionConfig ['policy']:\n",
            "  Configuration class for DiffusionPolicy.\n",
            "  \n",
            "      Defaults are configured for training with PushT providing proprioceptive and single camera observations.\n",
            "  \n",
            "      The parameters you will most likely need to change are the ones which depend on the environment / sensors.\n",
            "      Those are: `input_shapes` and `output_shapes`.\n",
            "  \n",
            "      Notes on the inputs and outputs:\n",
            "          - \"observation.state\" is required as an input key.\n",
            "          - Either:\n",
            "              - At least one key starting with \"observation.image is required as an input.\n",
            "                AND/OR\n",
            "              - The key \"observation.environment_state\" is required as input.\n",
            "          - If there are multiple keys beginning with \"observation.image\" they are treated as multiple camera\n",
            "            views. Right now we only support all images having the same shape.\n",
            "          - \"action\" is required as an output key.\n",
            "  \n",
            "      Args:\n",
            "          n_obs_steps: Number of environment steps worth of observations to pass to the policy (takes the\n",
            "              current step and additional steps going back).\n",
            "          horizon: Diffusion model action prediction size as detailed in `DiffusionPolicy.select_action`.\n",
            "          n_action_steps: The number of action steps to run in the environment for one invocation of the policy.\n",
            "              See `DiffusionPolicy.select_action` for more details.\n",
            "          input_shapes: A dictionary defining the shapes of the input data for the policy. The key represents\n",
            "              the input data name, and the value is a list indicating the dimensions of the corresponding data.\n",
            "              For example, \"observation.image\" refers to an input from a camera with dimensions [3, 96, 96],\n",
            "              indicating it has three color channels and 96x96 resolution. Importantly, `input_shapes` doesn't\n",
            "              include batch dimension or temporal dimension.\n",
            "          output_shapes: A dictionary defining the shapes of the output data for the policy. The key represents\n",
            "              the output data name, and the value is a list indicating the dimensions of the corresponding data.\n",
            "              For example, \"action\" refers to an output shape of [14], indicating 14-dimensional actions.\n",
            "              Importantly, `output_shapes` doesn't include batch dimension or temporal dimension.\n",
            "          input_normalization_modes: A dictionary with key representing the modality (e.g. \"observation.state\"),\n",
            "              and the value specifies the normalization mode to apply. The two available modes are \"mean_std\"\n",
            "              which subtracts the mean and divides by the standard deviation and \"min_max\" which rescale in a\n",
            "              [-1, 1] range.\n",
            "          output_normalization_modes: Similar dictionary as `normalize_input_modes`, but to unnormalize to the\n",
            "              original scale. Note that this is also used for normalizing the training targets.\n",
            "          vision_backbone: Name of the torchvision resnet backbone to use for encoding images.\n",
            "          crop_shape: (H, W) shape to crop images to as a preprocessing step for the vision backbone. Must fit\n",
            "              within the image size. If None, no cropping is done.\n",
            "          crop_is_random: Whether the crop should be random at training time (it's always a center crop in eval\n",
            "              mode).\n",
            "          pretrained_backbone_weights: Pretrained weights from torchvision to initialize the backbone.\n",
            "              `None` means no pretrained weights.\n",
            "          use_group_norm: Whether to replace batch normalization with group normalization in the backbone.\n",
            "              The group sizes are set to be about 16 (to be precise, feature_dim // 16).\n",
            "          spatial_softmax_num_keypoints: Number of keypoints for SpatialSoftmax.\n",
            "          use_separate_rgb_encoders_per_camera: Whether to use a separate RGB encoder for each camera view.\n",
            "          down_dims: Feature dimension for each stage of temporal downsampling in the diffusion modeling Unet.\n",
            "              You may provide a variable number of dimensions, therefore also controlling the degree of\n",
            "              downsampling.\n",
            "          kernel_size: The convolutional kernel size of the diffusion modeling Unet.\n",
            "          n_groups: Number of groups used in the group norm of the Unet's convolutional blocks.\n",
            "          diffusion_step_embed_dim: The Unet is conditioned on the diffusion timestep via a small non-linear\n",
            "              network. This is the output dimension of that network, i.e., the embedding dimension.\n",
            "          use_film_scale_modulation: FiLM (https://huggingface.co/papers/1709.07871) is used for the Unet conditioning.\n",
            "              Bias modulation is used be default, while this parameter indicates whether to also use scale\n",
            "              modulation.\n",
            "          noise_scheduler_type: Name of the noise scheduler to use. Supported options: [\"DDPM\", \"DDIM\"].\n",
            "          num_train_timesteps: Number of diffusion steps for the forward diffusion schedule.\n",
            "          beta_schedule: Name of the diffusion beta schedule as per DDPMScheduler from Hugging Face diffusers.\n",
            "          beta_start: Beta value for the first forward-diffusion step.\n",
            "          beta_end: Beta value for the last forward-diffusion step.\n",
            "          prediction_type: The type of prediction that the diffusion modeling Unet makes. Choose from \"epsilon\"\n",
            "              or \"sample\". These have equivalent outcomes from a latent variable modeling perspective, but\n",
            "              \"epsilon\" has been shown to work better in many deep neural network settings.\n",
            "          clip_sample: Whether to clip the sample to [-`clip_sample_range`, +`clip_sample_range`] for each\n",
            "              denoising step at inference time. WARNING: you will need to make sure your action-space is\n",
            "              normalized to fit within this range.\n",
            "          clip_sample_range: The magnitude of the clipping range as described above.\n",
            "          num_inference_steps: Number of reverse diffusion steps to use at inference time (steps are evenly\n",
            "              spaced). If not provided, this defaults to be the same as `num_train_timesteps`.\n",
            "          do_mask_loss_for_padding: Whether to mask the loss when there are copy-padded actions. See\n",
            "              `LeRobotDataset` and `load_previous_and_future_frames` for more information. Note, this defaults\n",
            "              to False as the original Diffusion Policy implementation does the same.\n",
            "      \n",
            "\n",
            "  --policy.n_obs_steps int\n",
            "  --policy.input_features Dict\n",
            "  --policy.output_features Dict\n",
            "  --policy.device [str]\n",
            "                        cuda | cpu | mp (default: None)\n",
            "  --policy.use_amp bool\n",
            "                        `use_amp` determines whether to use Automatic Mixed\n",
            "                        Precision (AMP) for training and evaluation. With AMP,\n",
            "                        automatic gradient scaling is used. (default: False)\n",
            "  --policy.push_to_hub bool\n",
            "  --policy.repo_id [str]\n",
            "  --policy.private [bool]\n",
            "                        Upload on private repository on the Hugging Face hub.\n",
            "                        (default: None)\n",
            "  --policy.tags [List]  Add tags to your policy on the hub. (default: None)\n",
            "  --policy.license [str]\n",
            "                        Add tags to your policy on the hub. (default: None)\n",
            "  --policy.pretrained_path [str]\n",
            "                        Either the repo ID of a model hosted on the Hub or a\n",
            "                        path to a directory containing weights saved using\n",
            "                        `Policy.save_pretrained`. If not provided, the policy\n",
            "                        is initialized from scratch. (default: None)\n",
            "  --policy.horizon int  \n",
            "  --policy.n_action_steps int\n",
            "  --policy.normalization_mapping Dict\n",
            "  --policy.drop_n_last_frames int\n",
            "                        horizon - n_action_steps - n_obs_steps + 1 (default:\n",
            "                        7)\n",
            "  --policy.vision_backbone str\n",
            "  --policy.crop_shape [int int]\n",
            "  --policy.crop_is_random bool\n",
            "  --policy.pretrained_backbone_weights [str]\n",
            "  --policy.use_group_norm bool\n",
            "  --policy.spatial_softmax_num_keypoints int\n",
            "  --policy.use_separate_rgb_encoder_per_camera bool\n",
            "  --policy.down_dims int [int, ...]\n",
            "  --policy.kernel_size int\n",
            "  --policy.n_groups int\n",
            "  --policy.diffusion_step_embed_dim int\n",
            "  --policy.use_film_scale_modulation bool\n",
            "  --policy.noise_scheduler_type str\n",
            "                        Noise scheduler. (default: DDPM)\n",
            "  --policy.num_train_timesteps int\n",
            "  --policy.beta_schedule str\n",
            "  --policy.beta_start float\n",
            "  --policy.beta_end float\n",
            "  --policy.prediction_type str\n",
            "  --policy.clip_sample bool\n",
            "  --policy.clip_sample_range float\n",
            "  --policy.num_inference_steps [int]\n",
            "  --policy.do_mask_loss_for_padding bool\n",
            "  --policy.optimizer_lr float\n",
            "                        Training presets (default: 0.0001)\n",
            "  --policy.optimizer_betas Any\n",
            "  --policy.optimizer_eps float\n",
            "  --policy.optimizer_weight_decay float\n",
            "  --policy.scheduler_name str\n",
            "  --policy.scheduler_warmup_steps int\n",
            "\n",
            "PI0Config ['policy']:\n",
            "\n",
            "  --policy.n_obs_steps int\n",
            "  --policy.input_features Dict\n",
            "  --policy.output_features Dict\n",
            "  --policy.device [str]\n",
            "                        Device to use for the model (None = auto-detect)\n",
            "                        (default: None)\n",
            "  --policy.use_amp bool\n",
            "                        `use_amp` determines whether to use Automatic Mixed\n",
            "                        Precision (AMP) for training and evaluation. With AMP,\n",
            "                        automatic gradient scaling is used. (default: False)\n",
            "  --policy.push_to_hub bool\n",
            "  --policy.repo_id [str]\n",
            "  --policy.private [bool]\n",
            "                        Upload on private repository on the Hugging Face hub.\n",
            "                        (default: None)\n",
            "  --policy.tags [List]  Add tags to your policy on the hub. (default: None)\n",
            "  --policy.license [str]\n",
            "                        Add tags to your policy on the hub. (default: None)\n",
            "  --policy.pretrained_path [str]\n",
            "                        Either the repo ID of a model hosted on the Hub or a\n",
            "                        path to a directory containing weights saved using\n",
            "                        `Policy.save_pretrained`. If not provided, the policy\n",
            "                        is initialized from scratch. (default: None)\n",
            "  --policy.paligemma_variant str\n",
            "  --policy.action_expert_variant str\n",
            "  --policy.dtype str    Options: \"bfloat16\", \"float32\" (default: float32)\n",
            "  --policy.chunk_size int\n",
            "                        Number of action steps to predict, in openpi called\n",
            "                        \"action_horizon\" (default: 50)\n",
            "  --policy.n_action_steps int\n",
            "                        Number of action steps to execute (default: 50)\n",
            "  --policy.max_state_dim int\n",
            "                        Shorter state and action vectors will be padded to\n",
            "                        these dimensions (default: 32)\n",
            "  --policy.max_action_dim int\n",
            "  --policy.num_inference_steps int\n",
            "                        Number of denoising steps during inference (default:\n",
            "                        10)\n",
            "  --policy.time_sampling_beta_alpha float\n",
            "  --policy.time_sampling_beta_beta float\n",
            "  --policy.time_sampling_scale float\n",
            "  --policy.time_sampling_offset float\n",
            "  --policy.min_period float\n",
            "  --policy.max_period float\n",
            "  --policy.image_resolution int int\n",
            "                        see openpi `preprocessing_pytorch.py` (default: (224,\n",
            "                        224))\n",
            "  --policy.empty_cameras int\n",
            "                        Add empty images. Used to add empty cameras when no\n",
            "                        image features are present. (default: 0)\n",
            "  --policy.normalization_mapping Dict\n",
            "                        Normalization (default: {'VISUAL':\n",
            "                        <NormalizationMode.IDENTITY: 'IDENTITY'>, 'STATE':\n",
            "                        <NormalizationMode.MEAN_STD: 'MEAN_STD'>, 'ACTION':\n",
            "                        <NormalizationMode.MEAN_STD: 'MEAN_STD'>})\n",
            "  --policy.gradient_checkpointing bool\n",
            "                        Enable gradient checkpointing for memory optimization\n",
            "                        (default: False)\n",
            "  --policy.compile_model bool\n",
            "                        Whether to use torch.compile for model optimization\n",
            "                        (default: False)\n",
            "  --policy.compile_mode str\n",
            "                        Torch compile mode (default: max-autotune)\n",
            "  --policy.optimizer_lr float\n",
            "                        see openpi `CosineDecaySchedule: peak_lr` (default:\n",
            "                        2.5e-05)\n",
            "  --policy.optimizer_betas float float\n",
            "  --policy.optimizer_eps float\n",
            "  --policy.optimizer_weight_decay float\n",
            "  --policy.optimizer_grad_clip_norm float\n",
            "  --policy.scheduler_warmup_steps int\n",
            "                        Scheduler settings: see openpi `CosineDecaySchedule`\n",
            "                        Note: These will auto-scale if --steps <\n",
            "                        scheduler_decay_steps For example, --steps=3000 will\n",
            "                        scale warmup to 100 and decay to 3000 (default: 1000)\n",
            "  --policy.scheduler_decay_steps int\n",
            "  --policy.scheduler_decay_lr float\n",
            "  --policy.tokenizer_max_length int\n",
            "                        see openpi `__post_init__` (default: 48)\n",
            "\n",
            "PI05Config ['policy']:\n",
            "\n",
            "  --policy.n_obs_steps int\n",
            "  --policy.input_features Dict\n",
            "  --policy.output_features Dict\n",
            "  --policy.device [str]\n",
            "                        Device to use for the model (None = auto-detect)\n",
            "                        (default: None)\n",
            "  --policy.use_amp bool\n",
            "                        `use_amp` determines whether to use Automatic Mixed\n",
            "                        Precision (AMP) for training and evaluation. With AMP,\n",
            "                        automatic gradient scaling is used. (default: False)\n",
            "  --policy.push_to_hub bool\n",
            "  --policy.repo_id [str]\n",
            "  --policy.private [bool]\n",
            "                        Upload on private repository on the Hugging Face hub.\n",
            "                        (default: None)\n",
            "  --policy.tags [List]  Add tags to your policy on the hub. (default: None)\n",
            "  --policy.license [str]\n",
            "                        Add tags to your policy on the hub. (default: None)\n",
            "  --policy.pretrained_path [str]\n",
            "                        Either the repo ID of a model hosted on the Hub or a\n",
            "                        path to a directory containing weights saved using\n",
            "                        `Policy.save_pretrained`. If not provided, the policy\n",
            "                        is initialized from scratch. (default: None)\n",
            "  --policy.paligemma_variant str\n",
            "  --policy.action_expert_variant str\n",
            "  --policy.dtype str    Options: \"bfloat16\", \"float32\" (default: float32)\n",
            "  --policy.chunk_size int\n",
            "                        Number of action steps to predict, in openpi called\n",
            "                        \"action_horizon\" (default: 50)\n",
            "  --policy.n_action_steps int\n",
            "                        Number of action steps to execute (default: 50)\n",
            "  --policy.max_state_dim int\n",
            "                        Shorter state and action vectors will be padded to\n",
            "                        these dimensions (default: 32)\n",
            "  --policy.max_action_dim int\n",
            "  --policy.num_inference_steps int\n",
            "                        Flow matching parameters: see openpi `PI0Pytorch`\n",
            "                        (default: 10)\n",
            "  --policy.time_sampling_beta_alpha float\n",
            "  --policy.time_sampling_beta_beta float\n",
            "  --policy.time_sampling_scale float\n",
            "  --policy.time_sampling_offset float\n",
            "  --policy.min_period float\n",
            "  --policy.max_period float\n",
            "  --policy.image_resolution int int\n",
            "                        see openpi `preprocessing_pytorch.py` (default: (224,\n",
            "                        224))\n",
            "  --policy.empty_cameras int\n",
            "                        Add empty images. Used to add empty cameras when no\n",
            "                        image features are present. (default: 0)\n",
            "  --policy.tokenizer_max_length int\n",
            "                        see openpi `__post_init__` (default: 200)\n",
            "  --policy.normalization_mapping Dict\n",
            "  --policy.gradient_checkpointing bool\n",
            "                        Enable gradient checkpointing for memory optimization\n",
            "                        (default: False)\n",
            "  --policy.compile_model bool\n",
            "                        Whether to use torch.compile for model optimization\n",
            "                        (default: False)\n",
            "  --policy.compile_mode str\n",
            "                        Torch compile mode (default: max-autotune)\n",
            "  --policy.optimizer_lr float\n",
            "                        see openpi `CosineDecaySchedule: peak_lr` (default:\n",
            "                        2.5e-05)\n",
            "  --policy.optimizer_betas float float\n",
            "  --policy.optimizer_eps float\n",
            "  --policy.optimizer_weight_decay float\n",
            "  --policy.optimizer_grad_clip_norm float\n",
            "  --policy.scheduler_warmup_steps int\n",
            "                        Scheduler settings: see openpi `CosineDecaySchedule`\n",
            "                        Note: These will auto-scale if --steps <\n",
            "                        scheduler_decay_steps For example, --steps=3000 will\n",
            "                        scale warmup to 100 and decay to 3000 (default: 1000)\n",
            "  --policy.scheduler_decay_steps int\n",
            "  --policy.scheduler_decay_lr float\n",
            "\n",
            "SmolVLAConfig ['policy']:\n",
            "\n",
            "  --policy.n_obs_steps int\n",
            "                        Input / output structure. (default: 1)\n",
            "  --policy.input_features Dict\n",
            "  --policy.output_features Dict\n",
            "  --policy.device [str]\n",
            "                        cuda | cpu | mp (default: None)\n",
            "  --policy.use_amp bool\n",
            "                        `use_amp` determines whether to use Automatic Mixed\n",
            "                        Precision (AMP) for training and evaluation. With AMP,\n",
            "                        automatic gradient scaling is used. (default: False)\n",
            "  --policy.push_to_hub bool\n",
            "  --policy.repo_id [str]\n",
            "  --policy.private [bool]\n",
            "                        Upload on private repository on the Hugging Face hub.\n",
            "                        (default: None)\n",
            "  --policy.tags [List]  Add tags to your policy on the hub. (default: None)\n",
            "  --policy.license [str]\n",
            "                        Add tags to your policy on the hub. (default: None)\n",
            "  --policy.pretrained_path [str]\n",
            "                        Either the repo ID of a model hosted on the Hub or a\n",
            "                        path to a directory containing weights saved using\n",
            "                        `Policy.save_pretrained`. If not provided, the policy\n",
            "                        is initialized from scratch. (default: None)\n",
            "  --policy.chunk_size int\n",
            "  --policy.n_action_steps int\n",
            "  --policy.normalization_mapping Dict\n",
            "  --policy.max_state_dim int\n",
            "                        Shorter state and action vectors will be padded\n",
            "                        (default: 32)\n",
            "  --policy.max_action_dim int\n",
            "  --policy.resize_imgs_with_padding int int\n",
            "                        Image preprocessing (default: (512, 512))\n",
            "  --policy.empty_cameras int\n",
            "                        Add empty images. Used by smolvla_aloha_sim which adds\n",
            "                        the empty left and right wrist cameras in addition to\n",
            "                        the top camera. (default: 0)\n",
            "  --policy.adapt_to_pi_aloha bool\n",
            "                        Converts the joint and gripper values from the\n",
            "                        standard Aloha space to the space used by the pi\n",
            "                        internal runtime which was used to train the base\n",
            "                        model. (default: False)\n",
            "  --policy.use_delta_joint_actions_aloha bool\n",
            "                        Converts joint dimensions to deltas with respect to\n",
            "                        the current state before passing to the model. Gripper\n",
            "                        dimensions will remain in absolute values. (default:\n",
            "                        False)\n",
            "  --policy.tokenizer_max_length int\n",
            "                        Tokenizer (default: 48)\n",
            "  --policy.num_steps int\n",
            "                        Decoding (default: 10)\n",
            "  --policy.use_cache bool\n",
            "                        Attention utils (default: True)\n",
            "  --policy.freeze_vision_encoder bool\n",
            "                        Finetuning settings (default: True)\n",
            "  --policy.train_expert_only bool\n",
            "  --policy.train_state_proj bool\n",
            "  --policy.optimizer_lr float\n",
            "                        Training presets (default: 0.0001)\n",
            "  --policy.optimizer_betas float float\n",
            "  --policy.optimizer_eps float\n",
            "  --policy.optimizer_weight_decay float\n",
            "  --policy.optimizer_grad_clip_norm float\n",
            "  --policy.scheduler_warmup_steps int\n",
            "  --policy.scheduler_decay_steps int\n",
            "  --policy.scheduler_decay_lr float\n",
            "  --policy.vlm_model_name str\n",
            "                        Select the VLM backbone. (default:\n",
            "                        HuggingFaceTB/SmolVLM2-500M-Video-Instruct)\n",
            "  --policy.load_vlm_weights bool\n",
            "                        Set to True in case of training the expert from\n",
            "                        scratch. True when init from pretrained SmolVLA\n",
            "                        weights (default: False)\n",
            "  --policy.add_image_special_tokens bool\n",
            "                        Whether to use special image tokens around image\n",
            "                        features. (default: False)\n",
            "  --policy.attention_mode str\n",
            "  --policy.prefix_length int\n",
            "  --policy.pad_language_to str\n",
            "                        \"max_length\" (default: longest)\n",
            "  --policy.num_expert_layers int\n",
            "                        Less or equal to 0 is the default where the action\n",
            "                        expert has the same number of layers of VLM. Otherwise\n",
            "                        the expert have less layers. (default: -1)\n",
            "  --policy.num_vlm_layers int\n",
            "                        Number of layers used in the VLM (first num_vlm_layers\n",
            "                        layers) (default: 16)\n",
            "  --policy.self_attn_every_n_layers int\n",
            "                        Interleave SA layers each self_attn_every_n_layers\n",
            "                        (default: 2)\n",
            "  --policy.expert_width_multiplier float\n",
            "                        The action expert hidden size (wrt to the VLM)\n",
            "                        (default: 0.75)\n",
            "  --policy.min_period float\n",
            "                        sensitivity range for the timestep used in sine-cosine\n",
            "                        positional encoding (default: 0.004)\n",
            "  --policy.max_period float\n",
            "\n",
            "TDMPCConfig ['policy']:\n",
            "  Configuration class for TDMPCPolicy.\n",
            "  \n",
            "      Defaults are configured for training with xarm_lift_medium_replay providing proprioceptive and single\n",
            "      camera observations.\n",
            "  \n",
            "      The parameters you will most likely need to change are the ones which depend on the environment / sensors.\n",
            "      Those are: `input_shapes`, `output_shapes`, and perhaps `max_random_shift_ratio`.\n",
            "  \n",
            "      Args:\n",
            "          n_action_repeats: The number of times to repeat the action returned by the planning. (hint: Google\n",
            "              action repeats in Q-learning or ask your favorite chatbot)\n",
            "          horizon: Horizon for model predictive control.\n",
            "          n_action_steps: Number of action steps to take from the plan given by model predictive control. This\n",
            "              is an alternative to using action repeats. If this is set to more than 1, then we require\n",
            "              `n_action_repeats == 1`, `use_mpc == True` and `n_action_steps <= horizon`. Note that this\n",
            "              approach of using multiple steps from the plan is not in the original implementation.\n",
            "          input_shapes: A dictionary defining the shapes of the input data for the policy. The key represents\n",
            "              the input data name, and the value is a list indicating the dimensions of the corresponding data.\n",
            "              For example, \"observation.image\" refers to an input from a camera with dimensions [3, 96, 96],\n",
            "              indicating it has three color channels and 96x96 resolution. Importantly, `input_shapes` doesn't\n",
            "              include batch dimension or temporal dimension.\n",
            "          output_shapes: A dictionary defining the shapes of the output data for the policy. The key represents\n",
            "              the output data name, and the value is a list indicating the dimensions of the corresponding data.\n",
            "              For example, \"action\" refers to an output shape of [14], indicating 14-dimensional actions.\n",
            "              Importantly, `output_shapes` doesn't include batch dimension or temporal dimension.\n",
            "          input_normalization_modes: A dictionary with key representing the modality (e.g. \"observation.state\"),\n",
            "              and the value specifies the normalization mode to apply. The two available modes are \"mean_std\"\n",
            "              which subtracts the mean and divides by the standard deviation and \"min_max\" which rescale in a\n",
            "              [-1, 1] range. Note that here this defaults to None meaning inputs are not normalized. This is to\n",
            "              match the original implementation.\n",
            "          output_normalization_modes: Similar dictionary as `normalize_input_modes`, but to unnormalize to the\n",
            "              original scale. Note that this is also used for normalizing the training targets. NOTE: Clipping\n",
            "              to [-1, +1] is used during MPPI/CEM. Therefore, it is recommended that you stick with \"min_max\"\n",
            "              normalization mode here.\n",
            "          image_encoder_hidden_dim: Number of channels for the convolutional layers used for image encoding.\n",
            "          state_encoder_hidden_dim: Hidden dimension for MLP used for state vector encoding.\n",
            "          latent_dim: Observation's latent embedding dimension.\n",
            "          q_ensemble_size: Number of Q function estimators to use in an ensemble for uncertainty estimation.\n",
            "          mlp_dim: Hidden dimension of MLPs used for modelling the dynamics encoder, reward function, policy\n",
            "              (œÄ), Q ensemble, and V.\n",
            "          discount: Discount factor (Œ≥) to use for the reinforcement learning formalism.\n",
            "          use_mpc: Whether to use model predictive control. The alternative is to just sample the policy model\n",
            "              (œÄ) for each step.\n",
            "          cem_iterations: Number of iterations for the MPPI/CEM loop in MPC.\n",
            "          max_std: Maximum standard deviation for actions sampled from the gaussian PDF in CEM.\n",
            "          min_std: Minimum standard deviation for noise applied to actions sampled from the policy model (œÄ).\n",
            "              Doubles up as the minimum standard deviation for actions sampled from the gaussian PDF in CEM.\n",
            "          n_gaussian_samples: Number of samples to draw from the gaussian distribution every CEM iteration. Must\n",
            "              be non-zero.\n",
            "          n_pi_samples: Number of samples to draw from the policy / world model rollout every CEM iteration. Can\n",
            "              be zero.\n",
            "          uncertainty_regularizer_coeff: Coefficient for the uncertainty regularization used when estimating\n",
            "              trajectory values (this is the Œª coefficient in eqn 4 of FOWM).\n",
            "          n_elites: The number of elite samples to use for updating the gaussian parameters every CEM iteration.\n",
            "          elite_weighting_temperature: The temperature to use for softmax weighting (by trajectory value) of the\n",
            "              elites, when updating the gaussian parameters for CEM.\n",
            "          gaussian_mean_momentum: Momentum (Œ±) used for EMA updates of the mean parameter Œº of the gaussian\n",
            "              parameters optimized in CEM. Updates are calculated as Œº‚Åª ‚Üê Œ±Œº‚Åª + (1-Œ±)Œº.\n",
            "          max_random_shift_ratio: Maximum random shift (as a proportion of the image size) to apply to the\n",
            "              image(s) (in units of pixels) for training-time augmentation. If set to 0, no such augmentation\n",
            "              is applied. Note that the input images are assumed to be square for this augmentation.\n",
            "          reward_coeff: Loss weighting coefficient for the reward regression loss.\n",
            "          expectile_weight: Weighting (œÑ) used in expectile regression for the state value function (V).\n",
            "              v_pred < v_target is weighted by œÑ and v_pred >= v_target is weighted by (1-œÑ). œÑ is expected to\n",
            "              be in [0, 1]. Setting œÑ closer to 1 results in a more \"optimistic\" V. This is sensible to do\n",
            "              because v_target is obtained by evaluating the learned state-action value functions (Q) with\n",
            "              in-sample actions that may not be always optimal.\n",
            "          value_coeff: Loss weighting coefficient for both the state-action value (Q) TD loss, and the state\n",
            "              value (V) expectile regression loss.\n",
            "          consistency_coeff: Loss weighting coefficient for the consistency loss.\n",
            "          advantage_scaling: A factor by which the advantages are scaled prior to exponentiation for advantage\n",
            "              weighted regression of the policy (œÄ) estimator parameters. Note that the exponentiated advantages\n",
            "              are clamped at 100.0.\n",
            "          pi_coeff: Loss weighting coefficient for the action regression loss.\n",
            "          temporal_decay_coeff: Exponential decay coefficient for decaying the loss coefficient for future time-\n",
            "              steps. Hint: each loss computation involves `horizon` steps worth of actions starting from the\n",
            "              current time step.\n",
            "          target_model_momentum: Momentum (Œ±) used for EMA updates of the target models. Updates are calculated\n",
            "              as œï ‚Üê Œ±œï + (1-Œ±)Œ∏ where œï are the parameters of the target model and Œ∏ are the parameters of the\n",
            "              model being trained.\n",
            "      \n",
            "\n",
            "  --policy.n_obs_steps int\n",
            "                        Input / output structure. (default: 1)\n",
            "  --policy.input_features Dict\n",
            "  --policy.output_features Dict\n",
            "  --policy.device [str]\n",
            "                        cuda | cpu | mp (default: None)\n",
            "  --policy.use_amp bool\n",
            "                        `use_amp` determines whether to use Automatic Mixed\n",
            "                        Precision (AMP) for training and evaluation. With AMP,\n",
            "                        automatic gradient scaling is used. (default: False)\n",
            "  --policy.push_to_hub bool\n",
            "  --policy.repo_id [str]\n",
            "  --policy.private [bool]\n",
            "                        Upload on private repository on the Hugging Face hub.\n",
            "                        (default: None)\n",
            "  --policy.tags [List]  Add tags to your policy on the hub. (default: None)\n",
            "  --policy.license [str]\n",
            "                        Add tags to your policy on the hub. (default: None)\n",
            "  --policy.pretrained_path [str]\n",
            "                        Either the repo ID of a model hosted on the Hub or a\n",
            "                        path to a directory containing weights saved using\n",
            "                        `Policy.save_pretrained`. If not provided, the policy\n",
            "                        is initialized from scratch. (default: None)\n",
            "  --policy.n_action_repeats int\n",
            "  --policy.horizon int  \n",
            "  --policy.n_action_steps int\n",
            "  --policy.normalization_mapping Dict\n",
            "  --policy.image_encoder_hidden_dim int\n",
            "  --policy.state_encoder_hidden_dim int\n",
            "  --policy.latent_dim int\n",
            "  --policy.q_ensemble_size int\n",
            "  --policy.mlp_dim int  \n",
            "  --policy.discount float\n",
            "  --policy.use_mpc bool\n",
            "  --policy.cem_iterations int\n",
            "  --policy.max_std float\n",
            "  --policy.min_std float\n",
            "  --policy.n_gaussian_samples int\n",
            "  --policy.n_pi_samples int\n",
            "  --policy.uncertainty_regularizer_coeff float\n",
            "  --policy.n_elites int\n",
            "  --policy.elite_weighting_temperature float\n",
            "  --policy.gaussian_mean_momentum float\n",
            "  --policy.max_random_shift_ratio float\n",
            "  --policy.reward_coeff float\n",
            "  --policy.expectile_weight float\n",
            "  --policy.value_coeff float\n",
            "  --policy.consistency_coeff float\n",
            "  --policy.advantage_scaling float\n",
            "  --policy.pi_coeff float\n",
            "  --policy.temporal_decay_coeff float\n",
            "  --policy.target_model_momentum float\n",
            "  --policy.optimizer_lr float\n",
            "                        Training presets (default: 0.0003)\n",
            "\n",
            "VQBeTConfig ['policy']:\n",
            "  Configuration class for VQ-BeT.\n",
            "  \n",
            "      Defaults are configured for training with PushT providing proprioceptive and single camera observations.\n",
            "  \n",
            "      The parameters you will most likely need to change are the ones which depend on the environment / sensors.\n",
            "      Those are: `input_shapes` and `output_shapes`.\n",
            "  \n",
            "      Notes on the inputs and outputs:\n",
            "          - \"observation.state\" is required as an input key.\n",
            "          - At least one key starting with \"observation.image is required as an input.\n",
            "          - If there are multiple keys beginning with \"observation.image\" they are treated as multiple camera\n",
            "            views. Right now we only support all images having the same shape.\n",
            "          - \"action\" is required as an output key.\n",
            "  \n",
            "      Args:\n",
            "          n_obs_steps: Number of environment steps worth of observations to pass to the policy (takes the\n",
            "              current step and additional steps going back).\n",
            "          n_action_pred_token: Total number of current token and future tokens that VQ-BeT predicts.\n",
            "          action_chunk_size: Action chunk size of each action prediction token.\n",
            "          input_shapes: A dictionary defining the shapes of the input data for the policy.\n",
            "              The key represents the input data name, and the value is a list indicating the dimensions\n",
            "              of the corresponding data. For example, \"observation.image\" refers to an input from\n",
            "              a camera with dimensions [3, 96, 96], indicating it has three color channels and 96x96 resolution.\n",
            "              Importantly, shapes doesnt include batch dimension or temporal dimension.\n",
            "          output_shapes: A dictionary defining the shapes of the output data for the policy.\n",
            "              The key represents the output data name, and the value is a list indicating the dimensions\n",
            "              of the corresponding data. For example, \"action\" refers to an output shape of [14], indicating\n",
            "              14-dimensional actions. Importantly, shapes doesnt include batch dimension or temporal dimension.\n",
            "          input_normalization_modes: A dictionary with key representing the modality (e.g. \"observation.state\"),\n",
            "              and the value specifies the normalization mode to apply. The two available modes are \"mean_std\"\n",
            "              which subtracts the mean and divides by the standard deviation and \"min_max\" which rescale in a\n",
            "              [-1, 1] range.\n",
            "          output_normalization_modes: Similar dictionary as `normalize_input_modes`, but to unnormalize to the\n",
            "              original scale. Note that this is also used for normalizing the training targets.\n",
            "          vision_backbone: Name of the torchvision resnet backbone to use for encoding images.\n",
            "          crop_shape: (H, W) shape to crop images to as a preprocessing step for the vision backbone. Must fit\n",
            "              within the image size. If None, no cropping is done.\n",
            "          crop_is_random: Whether the crop should be random at training time (it's always a center crop in eval\n",
            "              mode).\n",
            "          pretrained_backbone_weights: Pretrained weights from torchvision to initialize the backbone.\n",
            "              `None` means no pretrained weights.\n",
            "          use_group_norm: Whether to replace batch normalization with group normalization in the backbone.\n",
            "              The group sizes are set to be about 16 (to be precise, feature_dim // 16).\n",
            "          spatial_softmax_num_keypoints: Number of keypoints for SpatialSoftmax.\n",
            "          n_vqvae_training_steps: Number of optimization steps for training Residual VQ.\n",
            "          vqvae_n_embed: Number of embedding vectors in the RVQ dictionary (each layer).\n",
            "          vqvae_embedding_dim: Dimension of each embedding vector in the RVQ dictionary.\n",
            "          vqvae_enc_hidden_dim: Size of hidden dimensions of Encoder / Decoder part of Residaul VQ-VAE\n",
            "          gpt_block_size: Max block size of minGPT (should be larger than the number of input tokens)\n",
            "          gpt_input_dim: Size of output input of GPT. This is also used as the dimension of observation features.\n",
            "          gpt_output_dim: Size of output dimension of GPT. This is also used as a input dimension of offset / bin prediction headers.\n",
            "          gpt_n_layer: Number of layers of GPT\n",
            "          gpt_n_head: Number of headers of GPT\n",
            "          gpt_hidden_dim: Size of hidden dimensions of GPT\n",
            "          dropout: Dropout rate for GPT\n",
            "          offset_loss_weight:  A constant that is multiplied to the offset loss\n",
            "          primary_code_loss_weight: A constant that is multiplied to the primary code prediction loss\n",
            "          secondary_code_loss_weight: A constant that is multiplied to the secondary code prediction loss\n",
            "          bet_softmax_temperature: Sampling temperature of code for rollout with VQ-BeT\n",
            "          sequentially_select: Whether select code of primary / secondary as sequentially (pick primary code,\n",
            "              and then select secodnary code), or at the same time.\n",
            "      \n",
            "\n",
            "  --policy.n_obs_steps int\n",
            "  --policy.input_features Dict\n",
            "  --policy.output_features Dict\n",
            "  --policy.device [str]\n",
            "                        cuda | cpu | mp (default: None)\n",
            "  --policy.use_amp bool\n",
            "                        `use_amp` determines whether to use Automatic Mixed\n",
            "                        Precision (AMP) for training and evaluation. With AMP,\n",
            "                        automatic gradient scaling is used. (default: False)\n",
            "  --policy.push_to_hub bool\n",
            "  --policy.repo_id [str]\n",
            "  --policy.private [bool]\n",
            "                        Upload on private repository on the Hugging Face hub.\n",
            "                        (default: None)\n",
            "  --policy.tags [List]  Add tags to your policy on the hub. (default: None)\n",
            "  --policy.license [str]\n",
            "                        Add tags to your policy on the hub. (default: None)\n",
            "  --policy.pretrained_path [str]\n",
            "                        Either the repo ID of a model hosted on the Hub or a\n",
            "                        path to a directory containing weights saved using\n",
            "                        `Policy.save_pretrained`. If not provided, the policy\n",
            "                        is initialized from scratch. (default: None)\n",
            "  --policy.n_action_pred_token int\n",
            "  --policy.action_chunk_size int\n",
            "  --policy.normalization_mapping Dict\n",
            "  --policy.vision_backbone str\n",
            "  --policy.crop_shape [int int]\n",
            "  --policy.crop_is_random bool\n",
            "  --policy.pretrained_backbone_weights [str]\n",
            "  --policy.use_group_norm bool\n",
            "  --policy.spatial_softmax_num_keypoints int\n",
            "  --policy.n_vqvae_training_steps int\n",
            "  --policy.vqvae_n_embed int\n",
            "  --policy.vqvae_embedding_dim int\n",
            "  --policy.vqvae_enc_hidden_dim int\n",
            "  --policy.gpt_block_size int\n",
            "  --policy.gpt_input_dim int\n",
            "  --policy.gpt_output_dim int\n",
            "  --policy.gpt_n_layer int\n",
            "  --policy.gpt_n_head int\n",
            "  --policy.gpt_hidden_dim int\n",
            "  --policy.dropout float\n",
            "  --policy.offset_loss_weight float\n",
            "  --policy.primary_code_loss_weight float\n",
            "  --policy.secondary_code_loss_weight float\n",
            "  --policy.bet_softmax_temperature float\n",
            "  --policy.sequentially_select bool\n",
            "  --policy.optimizer_lr float\n",
            "                        Training presets (default: 0.0001)\n",
            "  --policy.optimizer_betas Any\n",
            "  --policy.optimizer_eps float\n",
            "  --policy.optimizer_weight_decay float\n",
            "  --policy.optimizer_vqvae_lr float\n",
            "  --policy.optimizer_vqvae_weight_decay float\n",
            "  --policy.scheduler_warmup_steps int\n",
            "\n",
            "SACConfig ['policy']:\n",
            "  Soft Actor-Critic (SAC) configuration.\n",
            "  \n",
            "      SAC is an off-policy actor-critic deep RL algorithm based on the maximum entropy\n",
            "      reinforcement learning framework. It learns a policy and a Q-function simultaneously\n",
            "      using experience collected from the environment.\n",
            "  \n",
            "      This configuration class contains all the parameters needed to define a SAC agent,\n",
            "      including network architectures, optimization settings, and algorithm-specific\n",
            "      hyperparameters.\n",
            "      \n",
            "\n",
            "  --policy.n_obs_steps int\n",
            "  --policy.input_features Dict\n",
            "  --policy.output_features Dict\n",
            "  --policy.device str   Architecture specifics Device to run the model on\n",
            "                        (e.g., \"cuda\", \"cpu\") (default: cpu)\n",
            "  --policy.use_amp bool\n",
            "                        `use_amp` determines whether to use Automatic Mixed\n",
            "                        Precision (AMP) for training and evaluation. With AMP,\n",
            "                        automatic gradient scaling is used. (default: False)\n",
            "  --policy.push_to_hub bool\n",
            "  --policy.repo_id [str]\n",
            "  --policy.private [bool]\n",
            "                        Upload on private repository on the Hugging Face hub.\n",
            "                        (default: None)\n",
            "  --policy.tags [List]  Add tags to your policy on the hub. (default: None)\n",
            "  --policy.license [str]\n",
            "                        Add tags to your policy on the hub. (default: None)\n",
            "  --policy.pretrained_path [str]\n",
            "                        Either the repo ID of a model hosted on the Hub or a\n",
            "                        path to a directory containing weights saved using\n",
            "                        `Policy.save_pretrained`. If not provided, the policy\n",
            "                        is initialized from scratch. (default: None)\n",
            "  --policy.normalization_mapping Dict\n",
            "                        Mapping of feature types to normalization modes\n",
            "                        (default: {'VISUAL': <NormalizationMode.MEAN_STD:\n",
            "                        'MEAN_STD'>, 'STATE': <NormalizationMode.MIN_MAX:\n",
            "                        'MIN_MAX'>, 'ENV': <NormalizationMode.MIN_MAX:\n",
            "                        'MIN_MAX'>, 'ACTION': <NormalizationMode.MIN_MAX:\n",
            "                        'MIN_MAX'>})\n",
            "  --policy.dataset_stats [Dict]\n",
            "                        Statistics for normalizing different types of inputs\n",
            "                        (default: {'observation.image': {'mean': [0.485,\n",
            "                        0.456, 0.406], 'std': [0.229, 0.224, 0.225]},\n",
            "                        'observation.state': {'min': [0.0, 0.0], 'max': [1.0,\n",
            "                        1.0]}, 'action': {'min': [0.0, 0.0, 0.0], 'max': [1.0,\n",
            "                        1.0, 1.0]}})\n",
            "  --policy.storage_device str\n",
            "                        Device to store the model on (default: cpu)\n",
            "  --policy.vision_encoder_name [str]\n",
            "                        Name of the vision encoder model (Set to\n",
            "                        \"helper2424/resnet10\" for hil serl resnet10) (default:\n",
            "                        None)\n",
            "  --policy.freeze_vision_encoder bool\n",
            "                        Whether to freeze the vision encoder during training\n",
            "                        (default: True)\n",
            "  --policy.image_encoder_hidden_dim int\n",
            "                        Hidden dimension size for the image encoder (default:\n",
            "                        32)\n",
            "  --policy.shared_encoder bool\n",
            "                        Whether to use a shared encoder for actor and critic\n",
            "                        (default: True)\n",
            "  --policy.num_discrete_actions [int]\n",
            "                        Number of discrete actions, eg for gripper actions\n",
            "                        (default: None)\n",
            "  --policy.image_embedding_pooling_dim int\n",
            "                        Dimension of the image embedding pooling (default: 8)\n",
            "  --policy.online_steps int\n",
            "                        Training parameter Number of steps for online training\n",
            "                        (default: 1000000)\n",
            "  --policy.online_buffer_capacity int\n",
            "                        Capacity of the online replay buffer (default: 100000)\n",
            "  --policy.offline_buffer_capacity int\n",
            "                        Capacity of the offline replay buffer (default:\n",
            "                        100000)\n",
            "  --policy.async_prefetch bool\n",
            "                        Whether to use asynchronous prefetching for the\n",
            "                        buffers (default: False)\n",
            "  --policy.online_step_before_learning int\n",
            "                        Number of steps before learning starts (default: 100)\n",
            "  --policy.policy_update_freq int\n",
            "                        Frequency of policy updates (default: 1)\n",
            "  --policy.discount float\n",
            "                        SAC algorithm parameters Discount factor for the SAC\n",
            "                        algorithm (default: 0.99)\n",
            "  --policy.temperature_init float\n",
            "                        Initial temperature value (default: 1.0)\n",
            "  --policy.num_critics int\n",
            "                        Number of critics in the ensemble (default: 2)\n",
            "  --policy.num_subsample_critics [int]\n",
            "                        Number of subsampled critics for training (default:\n",
            "                        None)\n",
            "  --policy.critic_lr float\n",
            "                        Learning rate for the critic network (default: 0.0003)\n",
            "  --policy.actor_lr float\n",
            "                        Learning rate for the actor network (default: 0.0003)\n",
            "  --policy.temperature_lr float\n",
            "                        Learning rate for the temperature parameter (default:\n",
            "                        0.0003)\n",
            "  --policy.critic_target_update_weight float\n",
            "                        Weight for the critic target update (default: 0.005)\n",
            "  --policy.utd_ratio int\n",
            "                        Update-to-data ratio for the UTD algorithm (If you\n",
            "                        want enable utd_ratio, you need to set it to >1)\n",
            "                        (default: 1)\n",
            "  --policy.state_encoder_hidden_dim int\n",
            "                        Hidden dimension size for the state encoder (default:\n",
            "                        256)\n",
            "  --policy.latent_dim int\n",
            "                        Dimension of the latent space (default: 256)\n",
            "  --policy.target_entropy [float]\n",
            "                        Target entropy for the SAC algorithm (default: None)\n",
            "  --policy.use_backup_entropy bool\n",
            "                        Whether to use backup entropy for the SAC algorithm\n",
            "                        (default: True)\n",
            "  --policy.grad_clip_norm float\n",
            "                        Gradient clipping norm for the SAC algorithm (default:\n",
            "                        40.0)\n",
            "  --policy.use_torch_compile bool\n",
            "                        Optimizations (default: True)\n",
            "\n",
            "CriticNetworkConfig ['policy.critic_network_kwargs']:\n",
            "  Network configuration\n",
            "  Configuration for the critic network architecture\n",
            "\n",
            "  --policy.critic_network_kwargs.hidden_dims List\n",
            "  --policy.critic_network_kwargs.activate_final bool\n",
            "  --policy.critic_network_kwargs.final_activation [str]\n",
            "\n",
            "ActorNetworkConfig ['policy.actor_network_kwargs']:\n",
            "  Configuration for the actor network architecture\n",
            "\n",
            "  --policy.actor_network_kwargs.hidden_dims List\n",
            "  --policy.actor_network_kwargs.activate_final bool\n",
            "\n",
            "PolicyConfig ['policy.policy_kwargs']:\n",
            "  Configuration for the policy parameters\n",
            "\n",
            "  --policy.policy_kwargs.use_tanh_squash bool\n",
            "  --policy.policy_kwargs.std_min float\n",
            "  --policy.policy_kwargs.std_max float\n",
            "  --policy.policy_kwargs.init_final float\n",
            "\n",
            "CriticNetworkConfig ['policy.discrete_critic_network_kwargs']:\n",
            "  Configuration for the discrete critic network\n",
            "\n",
            "  --policy.discrete_critic_network_kwargs.hidden_dims List\n",
            "  --policy.discrete_critic_network_kwargs.activate_final bool\n",
            "  --policy.discrete_critic_network_kwargs.final_activation [str]\n",
            "\n",
            "ActorLearnerConfig ['policy.actor_learner_config']:\n",
            "  Configuration for actor-learner architecture\n",
            "\n",
            "  --policy.actor_learner_config.learner_host str\n",
            "  --policy.actor_learner_config.learner_port int\n",
            "  --policy.actor_learner_config.policy_parameters_push_frequency int\n",
            "  --policy.actor_learner_config.queue_get_timeout float\n",
            "\n",
            "ConcurrencyConfig ['policy.concurrency']:\n",
            "  Configuration for concurrency settings (you can use threads or processes for the actor and learner)\n",
            "\n",
            "  --policy.concurrency.actor str\n",
            "  --policy.concurrency.learner str\n",
            "\n",
            "RewardClassifierConfig ['policy']:\n",
            "  Configuration for the Reward Classifier model.\n",
            "\n",
            "  --policy.n_obs_steps int\n",
            "  --policy.input_features Dict\n",
            "  --policy.output_features Dict\n",
            "  --policy.device str   \n",
            "  --policy.use_amp bool\n",
            "                        `use_amp` determines whether to use Automatic Mixed\n",
            "                        Precision (AMP) for training and evaluation. With AMP,\n",
            "                        automatic gradient scaling is used. (default: False)\n",
            "  --policy.push_to_hub bool\n",
            "  --policy.repo_id [str]\n",
            "  --policy.private [bool]\n",
            "                        Upload on private repository on the Hugging Face hub.\n",
            "                        (default: None)\n",
            "  --policy.tags [List]  Add tags to your policy on the hub. (default: None)\n",
            "  --policy.license [str]\n",
            "                        Add tags to your policy on the hub. (default: None)\n",
            "  --policy.pretrained_path [str]\n",
            "                        Either the repo ID of a model hosted on the Hub or a\n",
            "                        path to a directory containing weights saved using\n",
            "                        `Policy.save_pretrained`. If not provided, the policy\n",
            "                        is initialized from scratch. (default: None)\n",
            "  --policy.name str     \n",
            "  --policy.num_classes int\n",
            "  --policy.hidden_dim int\n",
            "  --policy.latent_dim int\n",
            "  --policy.image_embedding_pooling_dim int\n",
            "  --policy.dropout_rate float\n",
            "  --policy.model_name str\n",
            "  --policy.model_type str\n",
            "                        \"transformer\" or \"cnn\" (default: cnn)\n",
            "  --policy.num_cameras int\n",
            "  --policy.learning_rate float\n",
            "  --policy.weight_decay float\n",
            "  --policy.grad_clip_norm float\n",
            "  --policy.normalization_mapping Dict\n",
            "\n",
            "Optional ['optimizer']:\n",
            "\n",
            "OptimizerConfig ['optimizer']:\n",
            "\n",
            "  --optimizer.type {adam,adamw,sgd,multi_adam}\n",
            "                        Which type of OptimizerConfig ['optimizer'] to use\n",
            "                        (default: None)\n",
            "\n",
            "AdamConfig ['optimizer']:\n",
            "\n",
            "  --optimizer.lr float  \n",
            "  --optimizer.weight_decay float\n",
            "  --optimizer.grad_clip_norm float\n",
            "  --optimizer.betas float float\n",
            "  --optimizer.eps float\n",
            "\n",
            "AdamWConfig ['optimizer']:\n",
            "\n",
            "  --optimizer.lr float  \n",
            "  --optimizer.weight_decay float\n",
            "  --optimizer.grad_clip_norm float\n",
            "  --optimizer.betas float float\n",
            "  --optimizer.eps float\n",
            "\n",
            "SGDConfig ['optimizer']:\n",
            "\n",
            "  --optimizer.lr float  \n",
            "  --optimizer.weight_decay float\n",
            "  --optimizer.grad_clip_norm float\n",
            "  --optimizer.momentum float\n",
            "  --optimizer.dampening float\n",
            "  --optimizer.nesterov bool\n",
            "\n",
            "MultiAdamConfig ['optimizer']:\n",
            "  Configuration for multiple Adam optimizers with different parameter groups.\n",
            "  \n",
            "      This creates a dictionary of Adam optimizers, each with its own hyperparameters.\n",
            "  \n",
            "      Args:\n",
            "          lr: Default learning rate (used if not specified for a group)\n",
            "          weight_decay: Default weight decay (used if not specified for a group)\n",
            "          optimizer_groups: Dictionary mapping parameter group names to their hyperparameters\n",
            "          grad_clip_norm: Gradient clipping norm\n",
            "      \n",
            "\n",
            "  --optimizer.lr float  \n",
            "  --optimizer.weight_decay float\n",
            "  --optimizer.grad_clip_norm float\n",
            "                        lr: float = 1e-3 weight_decay: float = 0.0\n",
            "                        grad_clip_norm: float = 10.0 optimizer_groups:\n",
            "                        dict[str, dict[str, Any]] =\n",
            "                        field(default_factory=dict) def build(self,\n",
            "                        params_dict: dict[str, list]) -> dict[str,\n",
            "                        torch.optim.Optimizer]: (default: 10.0)\n",
            "  --optimizer.optimizer_groups Dict\n",
            "\n",
            "Optional ['scheduler']:\n",
            "\n",
            "LRSchedulerConfig ['scheduler']:\n",
            "\n",
            "  --scheduler.type {diffuser,vqbet,cosine_decay_with_warmup}\n",
            "                        Which type of LRSchedulerConfig ['scheduler'] to use\n",
            "                        (default: None)\n",
            "\n",
            "DiffuserSchedulerConfig ['scheduler']:\n",
            "\n",
            "  --scheduler.num_warmup_steps [int]\n",
            "  --scheduler.name str  \n",
            "\n",
            "VQBeTSchedulerConfig ['scheduler']:\n",
            "\n",
            "  --scheduler.num_warmup_steps int\n",
            "  --scheduler.num_vqvae_training_steps int\n",
            "  --scheduler.num_cycles float\n",
            "\n",
            "CosineDecayWithWarmupSchedulerConfig ['scheduler']:\n",
            "  Used by Physical Intelligence to train Pi0.\n",
            "  \n",
            "      Automatically scales warmup and decay steps if num_training_steps < num_decay_steps.\n",
            "      This ensures the learning rate schedule completes properly even with shorter training runs.\n",
            "      \n",
            "\n",
            "  --scheduler.num_warmup_steps int\n",
            "  --scheduler.num_decay_steps int\n",
            "  --scheduler.peak_lr float\n",
            "  --scheduler.decay_lr float\n",
            "\n",
            "EvalConfig ['eval']:\n",
            "\n",
            "  --eval.n_episodes int\n",
            "  --eval.batch_size int\n",
            "                        `batch_size` specifies the number of environments to\n",
            "                        use in a gym.vector.VectorEnv. (default: 50)\n",
            "  --eval.use_async_envs bool\n",
            "                        `use_async_envs` specifies whether to use asynchronous\n",
            "                        environments (multiprocessing). (default: False)\n",
            "\n",
            "WandBConfig ['wandb']:\n",
            "\n",
            "  --wandb.enable bool   \n",
            "  --wandb.disable_artifact bool\n",
            "                        Set to true to disable saving an artifact despite\n",
            "                        training.save_checkpoint=True (default: False)\n",
            "  --wandb.project str   \n",
            "  --wandb.entity [str]\n",
            "  --wandb.notes [str]\n",
            "  --wandb.run_id [str]\n",
            "  --wandb.mode [str]    Allowed values: 'online', 'offline' 'disabled'.\n",
            "                        Defaults to 'online' (default: None)\n"
          ]
        }
      ],
      "source": [
        "!cd /content/ && python lerobot/src/lerobot/scripts/lerobot_train.py -h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fO-09pwRiCoL"
      },
      "source": [
        "Test if gpu is available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "V2gnWWYtiCN6",
        "outputId": "19283ce7-6541-4fbb-afca-1239e260b6f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== üîç INFORMATIONS SYST√àME ===\n",
            "OS              : Linux 6.6.105+\n",
            "Version Python  : 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "------------------------------------------------------------\n",
            "=== ‚öôÔ∏è INFOS CUDA via PyTorch ===\n",
            "PyTorch version : 2.8.0+cu126\n",
            "CUDA disponible : True\n",
            "CUDA version    : 12.6\n",
            "CUDNN version   : 91002\n",
            "\n",
            "Nombre de GPU d√©tect√©s : 1\n",
            "\n",
            "--- GPU 0 ---\n",
            "Nom                : Tesla T4\n",
            "Capacit√© de calcul : 7.5\n",
            "M√©moire totale     : 14.74 Go\n",
            "Processeurs multi  : 40\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'torch._C._CudaDeviceProperties' object has no attribute 'clock_rate'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1761013667.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"M√©moire totale     : {props.total_memory / 1024**3:.2f} Go\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Processeurs multi  : {props.multi_processor_count}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Fr√©quence horloge  : {props.clock_rate / 1e3:.0f} MHz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'torch._C._CudaDeviceProperties' object has no attribute 'clock_rate'"
          ]
        }
      ],
      "source": [
        "# V√©rification de GPU CUDA avec le moins de d√©pendances possibles\n",
        "\n",
        "import platform\n",
        "import sys\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "print(\"=== üîç INFORMATIONS SYST√àME ===\")\n",
        "print(f\"OS              : {platform.system()} {platform.release()}\")\n",
        "print(f\"Version Python  : {sys.version}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Bloc 1 : PyTorch (si disponible)\n",
        "try:\n",
        "    import torch\n",
        "    print(\"=== ‚öôÔ∏è INFOS CUDA via PyTorch ===\")\n",
        "    print(f\"PyTorch version : {torch.__version__}\")\n",
        "    print(f\"CUDA disponible : {torch.cuda.is_available()}\")\n",
        "    print(f\"CUDA version    : {torch.version.cuda}\")\n",
        "    print(f\"CUDNN version   : {torch.backends.cudnn.version() if torch.backends.cudnn.is_available() else 'Non disponible'}\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        nb_gpus = torch.cuda.device_count()\n",
        "        print(f\"\\nNombre de GPU d√©tect√©s : {nb_gpus}\\n\")\n",
        "        for i in range(nb_gpus):\n",
        "            props = torch.cuda.get_device_properties(i)\n",
        "            print(f\"--- GPU {i} ---\")\n",
        "            print(f\"Nom                : {props.name}\")\n",
        "            print(f\"Capacit√© de calcul : {props.major}.{props.minor}\")\n",
        "            print(f\"M√©moire totale     : {props.total_memory / 1024**3:.2f} Go\")\n",
        "            print(f\"Processeurs multi  : {props.multi_processor_count}\")\n",
        "            print(f\"Fr√©quence horloge  : {props.clock_rate / 1e3:.0f} MHz\")\n",
        "            print()\n",
        "    else:\n",
        "        print(\"üö´ Aucun GPU CUDA d√©tect√© par PyTorch.\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"‚ùå PyTorch n'est pas install√© (import torch impossible).\")\n",
        "\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Bloc 2 : TensorFlow (si dispo)\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    print(\"=== üß† INFOS GPU via TensorFlow ===\")\n",
        "    print(f\"TensorFlow version : {tf.__version__}\")\n",
        "    gpus = tf.config.list_physical_devices('GPU')\n",
        "    print(f\"GPU d√©tect√©(s) : {len(gpus)}\")\n",
        "    for g in gpus:\n",
        "        print(f\" - {g}\")\n",
        "except ImportError:\n",
        "    print(\"‚ùå TensorFlow n'est pas install√© (import tensorflow impossible).\")\n",
        "\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Bloc 3 : NVIDIA-SMI (si disponible)\n",
        "print(\"=== üß© INFOS NVIDIA-SMI ===\")\n",
        "try:\n",
        "    result = subprocess.run([\"nvidia-smi\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "    if result.returncode == 0:\n",
        "        print(result.stdout)\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è La commande 'nvidia-smi' a √©chou√© :\")\n",
        "        print(result.stderr)\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå La commande 'nvidia-smi' n'est pas disponible sur ce syst√®me.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ufss6US6xbpi",
        "outputId": "d8028447-245e-4a30-f8a7-eaf356aa227f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 2025-10-18 14:18:09 ot_train.py:163 {'batch_size': 8,\n",
            " 'dataset': {'episodes': None,\n",
            "             'image_transforms': {'enable': False,\n",
            "                                  'max_num_transforms': 3,\n",
            "                                  'random_order': False,\n",
            "                                  'tfs': {'brightness': {'kwargs': {'brightness': [0.8,\n",
            "                                                                                   1.2]},\n",
            "                                                         'type': 'ColorJitter',\n",
            "                                                         'weight': 1.0},\n",
            "                                          'contrast': {'kwargs': {'contrast': [0.8,\n",
            "                                                                               1.2]},\n",
            "                                                       'type': 'ColorJitter',\n",
            "                                                       'weight': 1.0},\n",
            "                                          'hue': {'kwargs': {'hue': [-0.05,\n",
            "                                                                     0.05]},\n",
            "                                                  'type': 'ColorJitter',\n",
            "                                                  'weight': 1.0},\n",
            "                                          'saturation': {'kwargs': {'saturation': [0.5,\n",
            "                                                                                   1.5]},\n",
            "                                                         'type': 'ColorJitter',\n",
            "                                                         'weight': 1.0},\n",
            "                                          'sharpness': {'kwargs': {'sharpness': [0.5,\n",
            "                                                                                 1.5]},\n",
            "                                                        'type': 'SharpnessJitter',\n",
            "                                                        'weight': 1.0}}},\n",
            "             'repo_id': 'Heuzef/dataset_exemple_001',\n",
            "             'revision': None,\n",
            "             'root': None,\n",
            "             'streaming': False,\n",
            "             'use_imagenet_stats': True,\n",
            "             'video_backend': 'torchcodec'},\n",
            " 'env': None,\n",
            " 'eval': {'batch_size': 50, 'n_episodes': 50, 'use_async_envs': False},\n",
            " 'eval_freq': 20000,\n",
            " 'job_name': 'dataset_train_001',\n",
            " 'log_freq': 200,\n",
            " 'num_workers': 4,\n",
            " 'optimizer': {'betas': [0.9, 0.999],\n",
            "               'eps': 1e-08,\n",
            "               'grad_clip_norm': 10.0,\n",
            "               'lr': 1e-05,\n",
            "               'type': 'adamw',\n",
            "               'weight_decay': 0.0001},\n",
            " 'output_dir': 'outputs/train/dataset_exemple_001',\n",
            " 'policy': {'chunk_size': 100,\n",
            "            'device': 'cuda',\n",
            "            'dim_feedforward': 3200,\n",
            "            'dim_model': 512,\n",
            "            'dropout': 0.1,\n",
            "            'feedforward_activation': 'relu',\n",
            "            'input_features': {},\n",
            "            'kl_weight': 10.0,\n",
            "            'latent_dim': 32,\n",
            "            'license': None,\n",
            "            'n_action_steps': 100,\n",
            "            'n_decoder_layers': 1,\n",
            "            'n_encoder_layers': 4,\n",
            "            'n_heads': 8,\n",
            "            'n_obs_steps': 1,\n",
            "            'n_vae_encoder_layers': 4,\n",
            "            'normalization_mapping': {'ACTION': <NormalizationMode.MEAN_STD: 'MEAN_STD'>,\n",
            "                                      'STATE': <NormalizationMode.MEAN_STD: 'MEAN_STD'>,\n",
            "                                      'VISUAL': <NormalizationMode.MEAN_STD: 'MEAN_STD'>},\n",
            "            'optimizer_lr': 1e-05,\n",
            "            'optimizer_lr_backbone': 1e-05,\n",
            "            'optimizer_weight_decay': 0.0001,\n",
            "            'output_features': {},\n",
            "            'pre_norm': False,\n",
            "            'pretrained_backbone_weights': 'ResNet18_Weights.IMAGENET1K_V1',\n",
            "            'pretrained_path': None,\n",
            "            'private': None,\n",
            "            'push_to_hub': True,\n",
            "            'replace_final_stride_with_dilation': False,\n",
            "            'repo_id': 'Heuzef/act_policy_exemple_001',\n",
            "            'tags': None,\n",
            "            'temporal_ensemble_coeff': None,\n",
            "            'type': 'act',\n",
            "            'use_amp': False,\n",
            "            'use_vae': True,\n",
            "            'vision_backbone': 'resnet18'},\n",
            " 'resume': False,\n",
            " 'save_checkpoint': True,\n",
            " 'save_freq': 20000,\n",
            " 'scheduler': None,\n",
            " 'seed': 1000,\n",
            " 'steps': 100,\n",
            " 'use_policy_training_preset': True,\n",
            " 'wandb': {'disable_artifact': False,\n",
            "           'enable': False,\n",
            "           'entity': None,\n",
            "           'mode': None,\n",
            "           'notes': None,\n",
            "           'project': 'lerobot',\n",
            "           'run_id': None}}\n",
            "INFO 2025-10-18 14:18:09 ot_train.py:171 \u001b[1m\u001b[33mLogs will be saved locally.\u001b[0m\n",
            "INFO 2025-10-18 14:18:09 ot_train.py:183 Creating dataset\n",
            "INFO 2025-10-18 14:18:09 ot_train.py:202 Creating policy\n",
            "INFO 2025-10-18 14:18:10 ot_train.py:243 Creating optimizer and scheduler\n",
            "INFO 2025-10-18 14:18:10 ot_train.py:255 \u001b[1m\u001b[33mOutput dir:\u001b[0m outputs/train/dataset_exemple_001\n",
            "INFO 2025-10-18 14:18:10 ot_train.py:258 cfg.steps=100 (100)\n",
            "INFO 2025-10-18 14:18:10 ot_train.py:259 dataset.num_frames=246 (246)\n",
            "INFO 2025-10-18 14:18:10 ot_train.py:260 dataset.num_episodes=1\n",
            "INFO 2025-10-18 14:18:10 ot_train.py:263 Effective batch size: 8 x 1 = 8\n",
            "INFO 2025-10-18 14:18:10 ot_train.py:264 num_learnable_params=51597190 (52M)\n",
            "INFO 2025-10-18 14:18:10 ot_train.py:265 num_total_params=51597190 (52M)\n",
            "/usr/local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO 2025-10-18 14:18:10 ot_train.py:320 Start offline training on a fixed dataset\n",
            "INFO 2025-10-18 14:19:46 ot_train.py:357 Checkpoint policy after step 100\n",
            "INFO 2025-10-18 14:19:52 ot_train.py:426 End of training\n",
            "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            \n",
            "New Data Upload               : |          |  0.00B /  0.00B            \u001b[A\n",
            "\n",
            "  ...ple_001/model.safetensors:   0% 782k/207M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "Processing Files (0 / 1)      :   0% 782k/207M [00:01<04:25, 776kB/s,  977kB/s  ]\n",
            "\n",
            "  ...ple_001/model.safetensors:   0% 782k/207M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "Processing Files (0 / 1)      :   1% 1.34M/207M [00:01<03:24, 1.00MB/s, 1.12MB/s  ]\n",
            "New Data Upload               :   1% 563k/67.1M [00:01<02:46, 400kB/s,  469kB/s  ]\u001b[A\n",
            "\n",
            "Processing Files (0 / 1)      :   1% 1.91M/207M [00:01<02:28, 1.38MB/s, 1.36MB/s  ]\n",
            "New Data Upload               :   2% 1.13M/67.1M [00:01<01:21, 808kB/s,  804kB/s  ]\u001b[A\n",
            "\n",
            "Processing Files (0 / 1)      :   3% 5.29M/207M [00:01<00:41, 4.90MB/s, 3.30MB/s  ]\n",
            "New Data Upload               :   3% 4.51M/134M [00:01<00:32, 3.94MB/s, 2.82MB/s  ]\u001b[A\n",
            "\n",
            "Processing Files (0 / 1)      :   5% 10.9M/207M [00:02<00:18, 10.6MB/s, 6.07MB/s  ]\n",
            "New Data Upload               :   8% 10.1M/134M [00:02<00:13, 9.21MB/s, 5.63MB/s  ]\u001b[A\n",
            "\n",
            "Processing Files (0 / 1)      :   9% 18.2M/207M [00:02<00:10, 17.3MB/s, 9.12MB/s  ]\n",
            "New Data Upload               :  13% 17.5M/134M [00:02<00:07, 15.7MB/s, 8.73MB/s  ]\u001b[A\n",
            "\n",
            "Processing Files (0 / 1)      :  13% 26.7M/207M [00:02<00:07, 24.0MB/s, 12.1MB/s  ]\n",
            "New Data Upload               :  19% 25.9M/134M [00:02<00:04, 22.4MB/s, 11.8MB/s  ]\u001b[A\n",
            "\n",
            "Processing Files (0 / 1)      :  18% 37.3M/207M [00:02<00:05, 32.2MB/s, 15.6MB/s  ]\n",
            "New Data Upload               :  18% 36.6M/201M [00:02<00:05, 30.6MB/s, 15.2MB/s  ]\u001b[A\n",
            "\n",
            "Processing Files (0 / 1)      :  25% 52.0M/207M [00:02<00:03, 43.8MB/s, 20.0MB/s  ]\n",
            "New Data Upload               :  25% 51.1M/206M [00:02<00:03, 42.2MB/s, 19.7MB/s  ]\u001b[A\n",
            "\n",
            "Processing Files (0 / 1)      :  32% 66.0M/207M [00:03<00:02, 51.5MB/s, 23.6MB/s  ]\n",
            "New Data Upload               :  32% 65.1M/206M [00:03<00:02, 50.1MB/s, 23.3MB/s  ]\u001b[A\n",
            "\n",
            "Processing Files (0 / 1)      :  41% 85.0M/207M [00:03<00:01, 64.2MB/s, 28.3MB/s  ]\n",
            "New Data Upload               :  41% 84.2M/206M [00:03<00:01, 63.0MB/s, 28.1MB/s  ]\u001b[A\n",
            "\n",
            "Processing Files (0 / 1)      :  50% 103M/207M [00:03<00:01, 72.5MB/s, 32.3MB/s  ] \n",
            "New Data Upload               :  50% 103M/206M [00:03<00:01, 71.5MB/s, 32.1MB/s  ] \u001b[A\n",
            "\n",
            "Processing Files (0 / 1)      :  60% 124M/207M [00:03<00:01, 80.8MB/s, 36.4MB/s  ]\n",
            "New Data Upload               :  60% 123M/206M [00:03<00:01, 80.1MB/s, 36.1MB/s  ]\u001b[A\n",
            "\n",
            "Processing Files (0 / 1)      :  66% 136M/207M [00:03<00:00, 75.8MB/s, 37.9MB/s  ]\n",
            "New Data Upload               :  66% 136M/206M [00:03<00:00, 75.3MB/s, 37.7MB/s  ]\u001b[A\n",
            "\n",
            "Processing Files (0 / 1)      :  73% 151M/207M [00:04<00:00, 75.1MB/s, 39.8MB/s  ]\n",
            "New Data Upload               :  73% 150M/206M [00:04<00:00, 74.8MB/s, 39.6MB/s  ]\u001b[A\n",
            "\n",
            "Processing Files (0 / 1)      :  80% 166M/207M [00:04<00:00, 75.2MB/s, 41.5MB/s  ]\n",
            "New Data Upload               :  80% 165M/206M [00:04<00:00, 74.9MB/s, 41.3MB/s  ]\u001b[A\n",
            "\n",
            "Processing Files (0 / 1)      :  87% 180M/207M [00:04<00:00, 73.6MB/s, 42.9MB/s  ]\n",
            "New Data Upload               :  87% 179M/206M [00:04<00:00, 73.5MB/s, 42.7MB/s  ]\u001b[A\n",
            "\n",
            "Processing Files (0 / 1)      :  90% 187M/207M [00:04<00:00, 61.5MB/s, 42.5MB/s  ]\n",
            "New Data Upload               :  90% 186M/206M [00:04<00:00, 61.4MB/s, 42.3MB/s  ]\u001b[A\n",
            "\n",
            "Processing Files (0 / 1)      :  94% 194M/207M [00:04<00:00, 53.2MB/s, 42.1MB/s  ]\n",
            "New Data Upload               :  94% 193M/206M [00:04<00:00, 53.1MB/s, 41.9MB/s  ]\u001b[A\n",
            "\n",
            "Processing Files (0 / 1)      :  97% 200M/207M [00:05<00:00, 47.3MB/s, 41.7MB/s  ]\n",
            "New Data Upload               :  97% 199M/206M [00:05<00:00, 47.3MB/s, 41.6MB/s  ]\u001b[A\n",
            "\n",
            "Processing Files (0 / 1)      : 100% 207M/207M [00:05<00:00, 42.5MB/s, 41.3MB/s  ]\n",
            "New Data Upload               : 100% 206M/206M [00:05<00:00, 42.5MB/s, 41.1MB/s  ]\u001b[A\n",
            "\n",
            "  ...ple_001/model.safetensors: 100% 207M/207M [00:04<00:00, 46.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "  ...ple_001/model.safetensors: 100% 207M/207M [00:04<00:00, 44.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "  ...ple_001/model.safetensors: 100% 207M/207M [00:04<00:00, 42.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Processing Files (1 / 1)      : 100% 207M/207M [00:06<00:00, 15.8MB/s, 35.6MB/s  ]\n",
            "New Data Upload               : 100% 206M/206M [00:06<00:00, 15.8MB/s, 35.5MB/s  ]\u001b[A\n",
            "\n",
            "  ...ple_001/model.safetensors: 100% 207M/207M [00:05<00:00, 39.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "  ...ple_001/model.safetensors: 100% 207M/207M [00:05<00:00, 38.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Processing Files (1 / 1)      : 100% 207M/207M [00:06<00:00, 32.3MB/s, 33.3MB/s  ]\n",
            "New Data Upload               : 100% 206M/206M [00:06<00:00, 32.1MB/s, 33.2MB/s  ]\n",
            "  ...ple_001/model.safetensors: 100% 207M/207M [00:05<00:00, 38.1MB/s]\n",
            "INFO 2025-10-18 14:20:05 etrained.py:237 Model pushed to https://huggingface.co/Heuzef/act_policy_exemple_001\n",
            "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            \n",
            "New Data Upload               : |          |  0.00B /  0.00B            \u001b[A\n",
            "\n",
            "  ...zer_processor.safetensors: 100% 4.25k/4.25k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "Processing Files (1 / 1)      : 100% 4.25k/4.25k [00:00<00:00, 26.1kB/s,   ???B/s  ]\n",
            "\n",
            "Processing Files (1 / 1)      : 100% 4.25k/4.25k [00:00<00:00, 20.9kB/s,  0.00B/s  ]\n",
            "New Data Upload               : |          |  0.00B /  0.00B,  0.00B/s  \n",
            "  ...zer_processor.safetensors: 100% 4.25k/4.25k [00:00<?, ?B/s]\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING 2025-10-18 14:20:06 /hf_api.py:4298 No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            \n",
            "New Data Upload               : |          |  0.00B /  0.00B            \u001b[A\n",
            "\n",
            "  ...zer_processor.safetensors: 100% 4.25k/4.25k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "Processing Files (1 / 1)      : 100% 4.25k/4.25k [00:00<00:00, 25.7kB/s,   ???B/s  ]\n",
            "\n",
            "Processing Files (1 / 1)      : 100% 4.25k/4.25k [00:00<00:00, 20.9kB/s,  0.00B/s  ]\n",
            "New Data Upload               : |          |  0.00B /  0.00B,  0.00B/s  \n",
            "  ...zer_processor.safetensors: 100% 4.25k/4.25k [00:00<?, ?B/s]\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING 2025-10-18 14:20:07 /hf_api.py:4298 No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        }
      ],
      "source": [
        "!rm -r /content/outputs/train/dataset_exemple_001\n",
        "!cd /content/ && python lerobot/src/lerobot/scripts/lerobot_train.py \\\n",
        "  --dataset.repo_id=Heuzef/dataset_exemple_001 \\\n",
        "  --policy.type=act \\\n",
        "  --output_dir=outputs/train/dataset_exemple_001  \\\n",
        "  --job_name=dataset_train_001 \\\n",
        "  --policy.device=cuda \\\n",
        "  --wandb.enable=false \\\n",
        "  --policy.repo_id=Heuzef/act_policy_exemple_001 \\\n",
        "  --step=100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8TqWFmuyBYl"
      },
      "source": [
        "## Login into Hugging Face Hub\n",
        "Now after training is done login into the Hugging Face hub and upload the last checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yu5khQGIHi6"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFMLGuVkH7UN"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli upload ${HF_USER}/il_sim_test0 \\\n",
        "  /content/lerobot/outputs/train/il_sim_test0/checkpoints/last/pretrained_model"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "MOJyX0CnwA5m"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "10c89a41e6534e8e89c0a7ca09915c5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ae3f6348d59401ead0cf95da0a2180c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66bfb26ad52b466b9fc02e3665af2854",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_44bcd9b678c843de85067e889b29269f",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "1b06f88ce19b41fb96f5b019b03af7fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_eccc1ecd96104b3fbe5997387eeeb604"
          }
        },
        "296f5243b2c14617a4a773dfe9cff433": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44bcd9b678c843de85067e889b29269f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57859a913e504d3eba4264d66241667c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_e5f3be57bd1b478080449631ab9459bd",
            "style": "IPY_MODEL_af792aab9cc9446d81bca00344784d3a",
            "tooltip": ""
          }
        },
        "66bfb26ad52b466b9fc02e3665af2854": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "708417bc6e3f4a21b12fd8486855eac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f21d38ab465c453ca72db1ccb11adf2c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bd35e0f2791c48b49c284be6530a5de3",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "790e449c8e094618951732971e6f5656": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_10c89a41e6534e8e89c0a7ca09915c5d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_efd5e00b93b546cd8031977947f36344",
            "value": ""
          }
        },
        "7acdf04f26024200acbe10230ff7b767": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_f8638c06a73644be9edf13ace66c7d33",
            "style": "IPY_MODEL_e3248b80e6d24eeb9a7ef4e26253a35d",
            "value": true
          }
        },
        "8f57fe58255049e4a5cb1a7e372e6970": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af792aab9cc9446d81bca00344784d3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "bd35e0f2791c48b49c284be6530a5de3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3248b80e6d24eeb9a7ef4e26253a35d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5f3be57bd1b478080449631ab9459bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eccc1ecd96104b3fbe5997387eeeb604": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "efd5e00b93b546cd8031977947f36344": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f21d38ab465c453ca72db1ccb11adf2c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f44eb5a19e0444e18b4fc3bdc8714260": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_296f5243b2c14617a4a773dfe9cff433",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8f57fe58255049e4a5cb1a7e372e6970",
            "value": "Connecting..."
          }
        },
        "f8638c06a73644be9edf13ace66c7d33": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
